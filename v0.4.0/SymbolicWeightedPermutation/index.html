<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Weighted permutation (symbolic) · Entropies.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Entropies.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Documentation</a></li><li><a class="tocitem" href="../histogram_estimation/">Histograms</a></li><li><a class="tocitem" href="../probabilities/">Probabilities</a></li><li><a class="tocitem" href="../generalized_entropy/">Generalized entropy</a></li><li><span class="tocitem">Estimators</span><ul><li><a class="tocitem" href="../CountOccurrences/">CountOccurrences (counting)</a></li><li><a class="tocitem" href="../SymbolicPermutation/">Permutation (symbolic)</a></li><li class="is-active"><a class="tocitem" href>Weighted permutation (symbolic)</a></li><li><a class="tocitem" href="../SymbolicAmplitudeAwarePermutation/">Amplitude-aware permutation (symbolic)</a></li><li><a class="tocitem" href="../VisitationFrequency/">Visitation frequency (binning)</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Estimators</a></li><li class="is-active"><a href>Weighted permutation (symbolic)</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Weighted permutation (symbolic)</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kahaaga/Entropies.jl/blob/master/docs/src/SymbolicWeightedPermutation.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Weighted-permutation-(symbolic)"><a class="docs-heading-anchor" href="#Weighted-permutation-(symbolic)">Weighted permutation (symbolic)</a><a id="Weighted-permutation-(symbolic)-1"></a><a class="docs-heading-anchor-permalink" href="#Weighted-permutation-(symbolic)" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="Entropies.SymbolicWeightedPermutation" href="#Entropies.SymbolicWeightedPermutation"><code>Entropies.SymbolicWeightedPermutation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SymbolicWeightedPermutation &lt;: PermutationProbabilityEstimator</code></pre><p>A symbolic, weighted permutation based probabilities/entropy estimator.</p><p><strong>Properties of original signal preserved</strong></p><p>Weighted permutations of a signal preserve not only ordinal patterns (sorting information),  but also encodes amplitude information. This implementation is based on Fadlallah et al.  (2013)<sup class="footnote-reference"><a id="citeref-Fadlallah2013" href="#footnote-Fadlallah2013">[Fadlallah2013]</a></sup>.</p><p><strong>Description</strong></p><p>Consider the <span>$n$</span>-element univariate time series <span>$\{x(t) = x_1, x_2, \ldots, x_n\}$</span>.  Let <span>$\mathbf{x_i}^{m, \tau} = \{x_j, x_{j+\tau}, \ldots, x_{j+(m-1)\tau}\}$</span> for  <span>$j = 1, 2, \ldots n - (m-1)\tau$</span> be the <span>$i$</span>-th state vector in a delay reconstruction  with embedding dimension <span>$m$</span> and reconstruction lag <span>$\tau$</span>. There are then  <span>$N = n - (m-1)\tau$</span> state vectors. </p><p>For an <span>$m$</span>-dimensional vector, there are <span>$m!$</span> possible ways of sorting it in ascending  order of magnitude. Each such possible sorting ordering is called a <em>motif</em>.  Let <span>$\pi_i^{m, \tau}$</span> denote the motif associated with the <span>$m$</span>-dimensional state  vector <span>$\mathbf{x_i}^{m, \tau}$</span>, and let <span>$R$</span> be the number of distinct motifs that  can be constructed from the <span>$N$</span> state vectors. Then there are at most <span>$R$</span> motifs;  <span>$R = N$</span> precisely when all motifs are unique, and <span>$R = 1$</span> when all motifs are the same.  Each unique motif <span>$\pi_i^{m, \tau}$</span> can be mapped to a unique integer symbol  <span>$0 \leq s_i \leq M!-1$</span>. Let <span>$S(\pi) : \mathbb{R}^m \to \mathbb{N}_0$</span> be the  function that maps the motif <span>$\pi$</span> to its symbol <span>$s$</span>, and let <span>$\Pi$</span> denote the set      of symbols <span>$\Pi = \{ s_i \}_{i\in \{ 1, \ldots, R\}}$</span>.</p><p>Weighted permutation entropy is computed analogously to regular permutation entropy, but  adds weights that encode amplitude information too:</p><div>\[p(\pi_i^{m, \tau}) = \dfrac{\sum_{k=1}^N \mathbf{1}_{u:S(u) = s_i} \left( \mathbf{x}_k^{m, \tau} \right) \, w_k}{\sum_{k=1}^N \mathbf{1}_{u:S(u) \in \Pi} \left( \mathbf{x}_k^{m, \tau} \right) \,w_k} = \dfrac{\sum_{k=1}^N \mathbf{1}_{u:S(u) = s_i} \left( \mathbf{x}_k^{m, \tau} \right) \, w_k}{\sum_{k=1}^N w_k}.\]</div><p>The weighted permutation entropy is equivalent to regular permutation entropy when weights  are positive and identical (<span>$w_j = \beta \,\,\, \forall \,\,\, j \leq N$</span> and  <span>$\beta &gt; 0)$</span>. Weights are dictated by the variance of the state vectors.</p><p>Let the aritmetic mean of state vector <span>$\mathbf{x}_i$</span> be denoted  by</p><div>\[\mathbf{\hat{x}}_j^{m, \tau} = \frac{1}{m} \sum_{k=1}^m x_{j + (k+1)\tau}.\]</div><p>Weights are then computed as </p><div>\[w_j = \dfrac{1}{m}\sum_{k=1}^m (x_{j+(k+1)\tau} - \mathbf{\hat{x}}_j^{m, \tau})^2.\]</div><div class="admonition is-category-question"><header class="admonition-header">Implementation details</header><div class="admonition-body"><p><em>Note: in equation 7, section III, of the original paper, the authors write</em></p><div>\[w_j = \dfrac{1}{m}\sum_{k=1}^m (x_{j-(k-1)\tau} - \mathbf{\hat{x}}_j^{m, \tau})^2.\]</div><p><em>But given the formula they give for the arithmetic mean, this is <strong>not</strong> the variance  of <span>$\mathbf{x}_i$</span>, because the indices are mixed: <span>$x_{j+(k-1)\tau}$</span> in the weights  formula, vs. <span>$x_{j+(k+1)\tau}$</span> in the arithmetic mean formula. This seems to imply  that amplitude information about previous delay vectors  are mixed with mean amplitude information about current vectors. The authors also mix the  terms &quot;vector&quot; and &quot;neighboring vector&quot; (but uses the same notation for both), making it  hard to interpret whether the sign switch is a typo or intended. Here, we use the notation  above, which actually computes the variance for <span>$\mathbf{x}_i$</span></em>.</p></div></div><p><strong>Estimation from univariate time series/datasets</strong></p><ul><li><p>To compute weighted permutation entropy for a univariate signal <code>x</code>, use the signature    <code>entropy(x::AbstractVector, est::SymbolicWeightedPermutation; τ::Int = 1, m::Int = 3)</code>.</p></li><li><p>The corresponding (unordered) probability distribution of the permutation symbols for a    univariate signal <code>x</code> can be computed using <code>probabilities(x::AbstractVector,    est::SymbolicWeightedPermutation; τ::Int = 1, m::Int = 3)</code>.  </p></li></ul><div class="admonition is-info"><header class="admonition-header">Default embedding dimension and embedding lag</header><div class="admonition-body"><p>By default, embedding dimension <span>$m = 3$</span> with embedding lag <span>$\tau = 1$</span> is used. You  should probably make a more informed decision about embedding parameters when computing the  permutation entropy of a real dataset. In all cases, <span>$m$</span> must be at least 2 (there are  no permutations of a single-element state vector, so need <span>$m \geq 2$</span>).</p></div></div><p><strong>Estimation from multivariate time series/datasets</strong></p><p>Although not dealt with in the original paper, numerically speaking, weighted permutation  entropy, just like regular permutation entropy, can also be computed for multivariate  datasets (either embedded or consisting of multiple time series  variables). This assumes that the mixed symbols described above are actually a typo.</p><p>Then, just skip the delay reconstruction step, compute symbols  directly from the <span>$L$</span> existing state vectors  <span>$\{\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x_L}\}$</span>, symbolize  each <span>$\mathbf{x_i}$</span> precisely as above, then compute the  quantity </p><div>\[H = - \sum_j p(\pi) \ln p(\pi_j).\]</div><ul><li><p>To compute weighted permutation entropy for a multivariate/embedded dataset <code>x</code>, use the    signature <code>entropy(x::AbstractDataset, est::SymbolicWeightedPermutation)</code>.</p></li><li><p>To get the corresponding probability distribution for a multivariate/embedded dataset <code>x</code>,    use <code>probabilities(x::AbstractDataset, est::SymbolicWeightedPermutation)</code>.</p></li></ul><div class="admonition is-category-warn"><header class="admonition-header">Dynamical interpretation</header><div class="admonition-body"><p>A dynamical interpretation of the permutation entropy does not necessarily hold if  computing it on generic multivariate datasets. Method signatures for <code>Dataset</code>s are  provided for convenience, and should only be applied if you understand the relation  between your input data, the numerical value for the weighted permutation entropy, and  its interpretation.</p></div></div><p>See also: <a href="../SymbolicPermutation/#Entropies.SymbolicPermutation"><code>SymbolicPermutation</code></a>, <a href="../SymbolicAmplitudeAwarePermutation/#Entropies.SymbolicAmplitudeAwarePermutation"><code>SymbolicAmplitudeAwarePermutation</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/Entropies.jl/blob/1d84927452d425324261d2bb8a38682e93d29fb0/src/symbolic/SymbolicWeightedPermutation.jl#L9-L129">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Fadlallah2013"><a class="tag is-link" href="#citeref-Fadlallah2013">Fadlallah2013</a>Fadlallah, Bilal, et al. &quot;Weighted-permutation entropy: A complexity  measure for time series incorporating amplitude information.&quot; Physical  Review E 87.2 (2013): 022911.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../SymbolicPermutation/">« Permutation (symbolic)</a><a class="docs-footer-nextpage" href="../SymbolicAmplitudeAwarePermutation/">Amplitude-aware permutation (symbolic) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 5 November 2020 01:00">Thursday 5 November 2020</span>. Using Julia version 1.5.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
