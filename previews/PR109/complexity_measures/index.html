<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Complexity measures · Entropies.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Entropies.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Entropies.jl</a></li><li><a class="tocitem" href="../probabilities/">Probabilities</a></li><li><a class="tocitem" href="../entropies/">Entropies</a></li><li class="is-active"><a class="tocitem" href>Complexity measures</a><ul class="internal"><li><a class="tocitem" href="#Reverse-dispersion-entropy"><span>Reverse dispersion entropy</span></a></li></ul></li><li><a class="tocitem" href="../examples/">Entropies.jl examples</a></li><li><a class="tocitem" href="../utils/">Utility methods</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Complexity measures</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Complexity measures</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/Entropies.jl/blob/main/docs/src/complexity_measures.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="complexity_measures"><a class="docs-heading-anchor" href="#complexity_measures">Complexity measures</a><a id="complexity_measures-1"></a><a class="docs-heading-anchor-permalink" href="#complexity_measures" title="Permalink"></a></h1><h2 id="Reverse-dispersion-entropy"><a class="docs-heading-anchor" href="#Reverse-dispersion-entropy">Reverse dispersion entropy</a><a id="Reverse-dispersion-entropy-1"></a><a class="docs-heading-anchor-permalink" href="#Reverse-dispersion-entropy" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="Entropies.reverse_dispersion" href="#Entropies.reverse_dispersion"><code>Entropies.reverse_dispersion</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">reverse_dispersion(x::AbstractVector{T}, est::Dispersion = Dispersion();
    normalize = true) where T &lt;: Real</code></pre><p>Compute the reverse dispersion entropy complexity measure (Li et al., 2019)<sup class="footnote-reference"><a id="citeref-Li2019" href="#footnote-Li2019">[Li2019]</a></sup>.</p><p><strong>Description</strong></p><p>Li et al. (2021)<sup class="footnote-reference"><a id="citeref-Li2019" href="#footnote-Li2019">[Li2019]</a></sup> defines the reverse dispersion entropy as</p><p class="math-container">\[H_{rde} = \sum_{i = 1}^{c^m} \left(p_i - \dfrac{1}{{c^m}} \right)^2 =
\left( \sum_{i=1}^{c^m} p_i^2 \right) - \dfrac{1}{c^{m}}\]</p><p>where the probabilities <span>$p_i$</span> are obtained precisely as for the <a href="../probabilities/#Entropies.Dispersion"><code>Dispersion</code></a> probability estimator. Relative frequencies of dispersion patterns are computed using the given <code>symbolization</code> scheme , which defaults to symbolization using the normal cumulative distribution function (NCDF), as implemented by <a href="../utils/#Entropies.GaussianSymbolization"><code>GaussianSymbolization</code></a>, using embedding dimension <code>m</code> and embedding delay <code>τ</code>. Recommended parameter values<sup class="footnote-reference"><a id="citeref-Li2018" href="#footnote-Li2018">[Li2018]</a></sup> are <code>m ∈ [2, 3]</code>, <code>τ = 1</code> for the embedding, and <code>c ∈ [3, 4, …, 8]</code> categories for the Gaussian mapping.</p><p>If <code>normalize == true</code>, then the reverse dispersion entropy is normalized to <code>[0, 1]</code>.</p><p>The minimum value of <span>$H_{rde}$</span> is zero and occurs precisely when the dispersion pattern distribution is flat, which occurs when all <span>$p_i$</span>s are equal to <span>$1/c^m$</span>. Because <span>$H_{rde} \geq 0$</span>, <span>$H_{rde}$</span> can therefore be said to be a measure of how far the dispersion pattern probability distribution is from white noise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/Entropies.jl/blob/6341ca6fa2f5de122cf9785b7b8386efec9b1daf/src/complexity_measures/reverse_dispersion_entropy.jl#L35-L66">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Entropies.distance_to_whitenoise" href="#Entropies.distance_to_whitenoise"><code>Entropies.distance_to_whitenoise</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">distance_to_whitenoise(p::Probabilities, estimator::Dispersion; normalize = false)</code></pre><p>Compute the distance of the probability distribution <code>p</code> from a uniform distribution, given the parameters of <code>estimator</code> (which must be known beforehand).</p><p>If <code>normalize == true</code>, then normalize the value to the interval <code>[0, 1]</code> by using the parameters of <code>estimator</code>.</p><p>Used to compute reverse dispersion entropy(<a href="#Entropies.reverse_dispersion"><code>reverse_dispersion</code></a>; Li et al., 2019<sup class="footnote-reference"><a id="citeref-Li2019" href="#footnote-Li2019">[Li2019]</a></sup>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/Entropies.jl/blob/6341ca6fa2f5de122cf9785b7b8386efec9b1daf/src/complexity_measures/reverse_dispersion_entropy.jl#L6-L20">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Li2019"><a class="tag is-link" href="#citeref-Li2019">Li2019</a>Li, Y., Gao, X., &amp; Wang, L. (2019). Reverse dispersion entropy: a new complexity measure for sensor signal. Sensors, 19(23), 5203.</li><li class="footnote" id="footnote-Li2019"><a class="tag is-link" href="#citeref-Li2019">Li2019</a>Li, Y., Gao, X., &amp; Wang, L. (2019). Reverse dispersion entropy: a new complexity measure for sensor signal. Sensors, 19(23), 5203.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../entropies/">« Entropies</a><a class="docs-footer-nextpage" href="../examples/">Entropies.jl examples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Thursday 29 September 2022 13:49">Thursday 29 September 2022</span>. Using Julia version 1.8.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
