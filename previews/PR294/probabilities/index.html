<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Probabilities · ComplexityMeasures.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">ComplexityMeasures.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">ComplexityMeasures.jl</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li class="is-active"><a class="tocitem" href>Probabilities</a><ul class="internal"><li><a class="tocitem" href="#outcome_spaces"><span>Outcome spaces</span></a></li><li><a class="tocitem" href="#Probabilities"><span>Probabilities</span></a></li><li><a class="tocitem" href="#Counts"><span>Counts</span></a></li><li><a class="tocitem" href="#probability_estimators"><span>Probability estimators</span></a></li><li><a class="tocitem" href="#encodings"><span>Encodings API</span></a></li></ul></li><li><a class="tocitem" href="../information_measures/">Information measures (entropies and co.)</a></li><li><a class="tocitem" href="../complexity/">Complexity measures</a></li><li><a class="tocitem" href="../convenience/">Convenience functions</a></li><li><a class="tocitem" href="../examples/">ComplexityMeasures.jl Examples</a></li><li><a class="tocitem" href="../devdocs/">ComplexityMeasures.jl Dev Docs</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Probabilities</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Probabilities</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/main/docs/src/probabilities.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="[Probabilities](@ref)"><a class="docs-heading-anchor" href="#[Probabilities](@ref)"><a href="#Probabilities">Probabilities</a></a><a id="[Probabilities](@ref)-1"></a><a class="docs-heading-anchor-permalink" href="#[Probabilities](@ref)" title="Permalink"></a></h1><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Be sure you have gone through the <a href="../tutorial/#Tutorial">Tutorial</a> before going through the API here to have a good idea of the terminology used in ComplexityMeasures.jl.</p></div></div><p>ComplexityMeasures.jl implements an interface for probabilities that exactly follows the mathematically rigorous formulation of <a href="https://en.wikipedia.org/wiki/Probability_space">probability spaces</a>. Probability spaces are formalized by an <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> <span>$\Omega$</span>, and the functions <a href="#ComplexityMeasures.counts"><code>counts</code></a> and <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> as well as derivative functions such as <a href="#ComplexityMeasures.allprobabilities_and_outcomes"><code>allprobabilities_and_outcomes</code></a>. The mathematical formulation of probabilities spaces is further enhanced by <a href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a> and its subtypes, which may correct theoretically known biases when estimating probabilities from finite data.</p><p>In reality, probabilities can be either discrete (<a href="https://en.wikipedia.org/wiki/Probability_mass_function">mass functions</a>) or continuous (<a href="https://en.wikipedia.org/wiki/Probability_density_function">density functions</a>). Currently in ComplexityMeasures.jl, only probability mass functions (i.e., countable <span>$\Omega$</span>) are implemented explicitly. Quantities that are estimated from probability density functions (i.e., uncountable <span>$\Omega$</span>) also exist and are implemented in ComplexityMeasures.jl. However, these are estimated by a one-step processes without the intermediate estimation of probabilities.</p><p>If <span>$\Omega$</span> is countable, the process of estimating the outcomes from input data is also called <em>discretization</em> of the input data.</p><h2 id="outcome_spaces"><a class="docs-heading-anchor" href="#outcome_spaces">Outcome spaces</a><a id="outcome_spaces-1"></a><a class="docs-heading-anchor-permalink" href="#outcome_spaces" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.OutcomeSpace" href="#ComplexityMeasures.OutcomeSpace"><code>ComplexityMeasures.OutcomeSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OutcomeSpace</code></pre><p>The supertype for all outcome space implementation.</p><p><strong>Description</strong></p><p>In ComplexityMeasures.jl, an outcome space defines a set of possible outcomes <span>$\Omega = \{\omega_1, \omega_2, \ldots, \omega_L \}$</span> (some form of discretization). In the literature, the outcome space is often called an &quot;alphabet&quot;, while each outcome is called a &quot;symbol&quot; or an &quot;event&quot;.</p><p>An outcome space also defines a set of rules for mapping input data to to each outcome <span>$\omega_i$</span> (i.e. <a href="#encodings">encoding</a>/discretizing).</p><p><strong>Implementations</strong></p><table><tr><th style="text-align: left">Outcome space</th><th style="text-align: left">Principle</th><th style="text-align: left">Input data</th><th style="text-align: left">Counting-compatible</th></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.CountOccurrences"><code>CountOccurrences</code></a></td><td style="text-align: left">Count of unique elements</td><td style="text-align: left"><code>Any</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a></td><td style="text-align: left">Binning (histogram)</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.TransferOperator"><code>TransferOperator</code></a></td><td style="text-align: left">Binning (transfer operator)</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.NaiveKernel"><code>NaiveKernel</code></a></td><td style="text-align: left">Kernel density estimation</td><td style="text-align: left"><code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.WeightedOrdinalPatterns"><code>WeightedOrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.AmplitudeAwareOrdinalPatterns"><code>AmplitudeAwareOrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.SpatialOrdinalPatterns"><code>SpatialOrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns in space</td><td style="text-align: left"><code>Array</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a></td><td style="text-align: left">Dispersion patterns</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.SpatialDispersion"><code>SpatialDispersion</code></a></td><td style="text-align: left">Dispersion patterns in space</td><td style="text-align: left"><code>Array</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.Diversity"><code>Diversity</code></a></td><td style="text-align: left">Cosine similarity</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.WaveletOverlap"><code>WaveletOverlap</code></a></td><td style="text-align: left">Wavelet transform</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.PowerSpectrum"><code>PowerSpectrum</code></a></td><td style="text-align: left">Fourier transform</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✖</td></tr></table><p>In the column &quot;input data&quot; it is assumed that the <code>eltype</code> of the input is <code>&lt;: Real</code>.</p><p><strong>Usage</strong></p><p>Outcome spaces are used as input to</p><ul><li><a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>/<a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a> for computing probability   mass functions.</li><li><a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a>, which returns the elements of the outcome space.</li><li><a href="#ComplexityMeasures.total_outcomes"><code>total_outcomes</code></a>, which returns the cardinality of the outcome space.</li><li><a href="#ComplexityMeasures.counts"><code>counts</code></a>/<a href="@ref"><code>allcounts</code></a>, for obtaining raw counts instead   of probabilities (only for counting-compatible outcome spaces).</li></ul><p><strong>Counting-compatible vs. non-counting compatible outcome spaces</strong></p><p>There are two main types of outcome spaces.</p><ul><li>Counting-compatible outcome spaces have a well-defined   way of counting how often each point in the (encoded) input data is mapped to a   particular outcome <span>$\omega_i$</span>. These outcome spaces use   <a href="#ComplexityMeasures.encode"><code>encode</code></a> to discretize the input data. Examples are   <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> (which encodes input data into ordinal patterns) or   <a href="#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a> (which discretizes points onto a regular grid).   The table below lists which outcome spaces are counting compatible.</li><li>Non-counting compatible outcome spaces have no well-defined way of counting explicitly   how often each point in the input data is mapped to a particular outcome <span>$\omega_i$</span>.   Instead, these outcome spaces returns a vector of pre-normalized &quot;relative counts&quot;, one   for each outcome <span>$\omega_i$</span>. Examples are <a href="#ComplexityMeasures.WaveletOverlap"><code>WaveletOverlap</code></a> or   <a href="#ComplexityMeasures.PowerSpectrum"><code>PowerSpectrum</code></a>.</li></ul><p>Counting-compatible outcome spaces can be used with <em>any</em> <a href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a> to convert counts into probability mass functions. Non-counting-compatible outcome spaces can only be used with the maximum likelihood (<a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a>) probabilities estimator, which estimates probabilities precisely by the relative frequency of each outcome (formally speaking, the <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a> estimator also requires counts, but for the sake of code consistency, we allow it to be used with relative frequencies as well).</p><p>The function <a href="#ComplexityMeasures.is_counting_based"><code>is_counting_based</code></a> can be used to check whether an outcome space is based on counting.</p><p><strong>Deducing the outcome space (from data)</strong></p><p>Some outcome space models can deduce <span>$\Omega$</span> without knowledge of the input, such as <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>. Other outcome spaces require knowledge of the input data for concretely specifying <span>$\Omega$</span>, such as <a href="#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a> with <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a>. If <code>o</code> is some outcome space model and <code>x</code> some input data, then <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a><code>(o, x)</code> returns the possible outcomes <span>$\Omega$</span>. To get the cardinality of <span>$\Omega$</span>, use <a href="#ComplexityMeasures.total_outcomes"><code>total_outcomes</code></a>.</p><p><strong>Implementation details</strong></p><p>The element type of <span>$\Omega$</span> varies between outcome space models, but it is guaranteed to be <em>hashable</em> and <em>sortable</em>. This allows for conveniently tracking the counts of a specific event across experimental realizations, by using the outcome as a dictionary key and the counts as the value for that key (or, alternatively, the key remains the outcome and one has a vector of probabilities, one for each experimental realization).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/outcome_spaces.jl#L6-L97">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.outcomes" href="#ComplexityMeasures.outcomes"><code>ComplexityMeasures.outcomes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">outcomes(o::OutcomeSpace, x)</code></pre><p>Return all (unique) outcomes that appears in the (encoded) input data <code>x</code>, according to the given <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>. Equivalent to <code>probabilities_and_outcomes(o, x)[2]</code>, but for some estimators it may be explicitly extended for better performance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/outcome_spaces.jl#L135-L142">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.outcome_space" href="#ComplexityMeasures.outcome_space"><code>ComplexityMeasures.outcome_space</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">outcome_space(o::OutcomeSpace, x) → Ω</code></pre><p>Return a sorted container containing all <em>possible</em> outcomes of <code>o</code> for input <code>x</code>.</p><p>For some estimators the concrete outcome space is known without knowledge of input <code>x</code>, in which case the function dispatches to <code>outcome_space(o)</code>. In general it is recommended to use the 2-argument version irrespectively of estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/outcome_spaces.jl#L106-L114">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.total_outcomes" href="#ComplexityMeasures.total_outcomes"><code>ComplexityMeasures.total_outcomes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">total_outcomes(o::OutcomeSpace, x)</code></pre><p>Return the length (cardinality) of the outcome space <span>$\Omega$</span> of <code>est</code>.</p><p>For some <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>, the cardinality is known without knowledge of input <code>x</code>, in which case the function dispatches to <code>total_outcomes(est)</code>. In general it is recommended to use the 2-argument version irrespectively of estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/outcome_spaces.jl#L123-L131">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.missing_outcomes" href="#ComplexityMeasures.missing_outcomes"><code>ComplexityMeasures.missing_outcomes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">missing_outcomes(o::OutcomeSpace, x; all = true) → n_missing::Int</code></pre><p>Count the number of missing (i.e., zero-probability) outcomes specified by <code>o</code>, given input data <code>x</code>, using <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a> probabilities estimation.</p><p>If <code>all == true</code>, then <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a> is used to compute the probabilities. If <code>all == false</code>, then <a href="@ ref"><code>probabilities</code></a> is used to compute the probabilities.</p><p>This is syntactically equivalent to <code>missing_outcomes(RelativeAmount(o), x)</code>.</p><pre><code class="nohighlight hljs">missing_outcomes(est::ProbabilitiesEstimator, x) → n_missing::Int</code></pre><p>Like above, but specifying a custom <a href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a>.</p><p>See also: <a href="../complexity/#ComplexityMeasures.MissingDispersionPatterns"><code>MissingDispersionPatterns</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L287-L304">source</a></section></article><h3 id="Count-occurrences"><a class="docs-heading-anchor" href="#Count-occurrences">Count occurrences</a><a id="Count-occurrences-1"></a><a class="docs-heading-anchor-permalink" href="#Count-occurrences" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.CountOccurrences" href="#ComplexityMeasures.CountOccurrences"><code>ComplexityMeasures.CountOccurrences</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CountOccurrences()</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on straight-forward counting of distinct elements in a univariate time series or multivariate dataset. This is the same as giving no estimator to <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>.</p><p><strong>Outcome space</strong></p><p>The outcome space is the unique sorted values of the input. Hence, input <code>x</code> is needed for a well-defined <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/count_occurences.jl#L3-L14">source</a></section></article><h3 id="Histograms"><a class="docs-heading-anchor" href="#Histograms">Histograms</a><a id="Histograms-1"></a><a class="docs-heading-anchor-permalink" href="#Histograms" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.ValueHistogram" href="#ComplexityMeasures.ValueHistogram"><code>ComplexityMeasures.ValueHistogram</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ValueHistogram(b::AbstractBinning) &lt;: OutcomeSpace</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on binning the values of the data as dictated by the binning scheme <code>b</code> and formally computing their histogram, i.e., the frequencies of points in the bins. An alias to this is <code>VisitationFrequency</code>. Available binnings are subtypes of <a href="#ComplexityMeasures.AbstractBinning"><code>AbstractBinning</code></a>.</p><p>The <code>ValueHistogram</code> estimator has a linearithmic time complexity (<code>n log(n)</code> for <code>n = length(x)</code>) and a linear space complexity (<code>l</code> for <code>l = dimension(x)</code>). This allows computation of probabilities (histograms) of high-dimensional datasets and with small box sizes <code>ε</code> without memory overflow and with maximum performance. For performance reasons, the probabilities returned never contain 0s and are arbitrarily ordered.</p><pre><code class="nohighlight hljs">ValueHistogram(ϵ::Union{Real,Vector})</code></pre><p>A convenience method that accepts same input as <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a> and initializes this binning directly.</p><p><strong>Outcomes</strong></p><p>The outcome space for <code>ValueHistogram</code> is the unique bins constructed from <code>b</code>. Each bin is identified by its left (lowest-value) corner, because bins are always left-closed-right-open intervals <code>[a, b)</code>. The bins are in data units, not integer (cartesian indices units), and are returned as <code>SVector</code>s, i.e., same type as input data.</p><p>For convenience, <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a> returns the outcomes in the same array format as the underlying binning (e.g., <code>Matrix</code> for 2D input).</p><p>For <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> the <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a> is well-defined from the binning, but for <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a> input <code>x</code> is needed as well.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/value_histogram.jl#L4-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.AbstractBinning" href="#ComplexityMeasures.AbstractBinning"><code>ComplexityMeasures.AbstractBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractBinning</code></pre><p>Supertype encompassing <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a> and <a href="@ref"><code>FixedRectangualrBinning</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/encoding_implementations/rectangular_binning.jl#L4-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.RectangularBinning" href="#ComplexityMeasures.RectangularBinning"><code>ComplexityMeasures.RectangularBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RectangularBinning(ϵ, precise = false) &lt;: AbstractBinning</code></pre><p>Rectangular box partition of state space using the scheme <code>ϵ</code>, deducing the histogram extent and bin width from the input data.</p><p><code>RectangularBinning</code> is a convenience struct. It is re-cast into <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> once the data are provided, so see that docstring for info on the bin calculation and the meaning of <code>precise</code>.</p><p>Binning instructions are deduced from the type of <code>ϵ</code> as follows:</p><ol><li><code>ϵ::Int</code> divides each coordinate axis into <code>ϵ</code> equal-length intervals  that cover all data.</li><li><code>ϵ::Float64</code> divides each coordinate axis into intervals of fixed size <code>ϵ</code>, starting  from the axis minima until the data is completely covered by boxes.</li><li><code>ϵ::Vector{Int}</code> divides the i-th coordinate axis into <code>ϵ[i]</code> equal-length  intervals that cover all data.</li><li><code>ϵ::Vector{Float64}</code> divides the i-th coordinate axis into intervals of fixed size  <code>ϵ[i]</code>, starting from the axis minima until the data is completely covered by boxes.</li></ol><p><code>RectangularBinning</code> ensures all input data are covered by extending the created ranges if need be.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/encoding_implementations/rectangular_binning.jl#L18-L42">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.FixedRectangularBinning" href="#ComplexityMeasures.FixedRectangularBinning"><code>ComplexityMeasures.FixedRectangularBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FixedRectangularBinning &lt;: AbstractBinning
FixedRectangularBinning(ranges::Tuple{&lt;:AbstractRange...}, precise = false)</code></pre><p>Rectangular box partition of state space where the partition along each dimension is explicitly given by each range <code>ranges</code>, which is a tuple of <code>AbstractRange</code> subtypes. Typically, each range is the output of the <code>range</code> Base function, e.g., <code>ranges = (0:0.1:1, range(0, 1; length = 101), range(2.1, 3.2; step = 0.33))</code>. All ranges must be sorted.</p><p>The optional second argument <code>precise</code> dictates whether Julia Base&#39;s <code>TwicePrecision</code> is used for when searching where a point falls into the range. Useful for edge cases of points being almost exactly on the bin edges, but it is exactly four times as slow, so by default it is <code>false</code>.</p><p>Points falling outside the partition do not contribute to probabilities. Bins are always left-closed-right-open: <code>[a, b)</code>. <strong>This means that the last value of each of the ranges dictates the last right-closing value.</strong> This value does <em>not</em> belong to the histogram! E.g., if given a range <code>r = range(0, 1; length = 11)</code>, with <code>r[end] = 1</code>, the value <code>1</code> is outside the partition and would not attribute any increase of the probability corresponding to the last bin (here <code>[0.9, 1)</code>)!</p><p><strong>Equivalently, the size of the histogram is <code>histsize = map(r -&gt; length(r)-1, ranges)</code>!</strong></p><p><code>FixedRectangularBinning</code> leads to a well-defined outcome space without knowledge of input data, see <a href="#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/encoding_implementations/rectangular_binning.jl#L49-L78">source</a></section></article><h3 id="Symbolic-permutations"><a class="docs-heading-anchor" href="#Symbolic-permutations">Symbolic permutations</a><a id="Symbolic-permutations-1"></a><a class="docs-heading-anchor-permalink" href="#Symbolic-permutations" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.OrdinalPatterns" href="#ComplexityMeasures.OrdinalPatterns"><code>ComplexityMeasures.OrdinalPatterns</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OrdinalPatterns &lt;: OutcomeSpace
OrdinalPatterns(; m = 3, τ = 1, lt::Function = ComplexityMeasures.isless_rand)</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on ordinal permutation patterns.</p><p>When passed to <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> the output depends on the input data type:</p><ul><li><strong>Univariate data</strong>. If applied to a univariate timeseries (<code>AbstractVector</code>), then the timeseries   is first embedded using embedding delay <code>τ</code> and dimension <code>m</code>, resulting in embedding   vectors <span>$\{ \bf{x}_i \}_{i=1}^{N-(m-1)\tau}$</span>. Then, for each <span>$\bf{x}_i$</span>,   we find its permutation pattern <span>$\pi_{i}$</span>. Probabilities are then   estimated as the frequencies of the encoded permutation symbols   by using <a href="#ComplexityMeasures.CountOccurrences"><code>CountOccurrences</code></a>. When giving the resulting probabilities to   <a href="../information_measures/#ComplexityMeasures.information-Tuple{InformationMeasure, OutcomeSpace, Any}"><code>information</code></a>, the original permutation entropy is computed <sup class="footnote-reference"><a id="citeref-BandtPompe2002" href="#footnote-BandtPompe2002">[BandtPompe2002]</a></sup>.</li><li><strong>Multivariate data</strong>. If applied to a an <code>D</code>-dimensional <code>StateSpaceSet</code>,   then no embedding is constructed, <code>m</code> must be equal to <code>D</code> and <code>τ</code> is ignored.   Each vector <span>$\bf{x}_i$</span> of the dataset is mapped   directly to its permutation pattern <span>$\pi_{i}$</span> by comparing the   relative magnitudes of the elements of <span>$\bf{x}_i$</span>.   Like above, probabilities are estimated as the frequencies of the permutation symbols.   The resulting probabilities can be used to compute multivariate permutation   entropy<sup class="footnote-reference"><a id="citeref-He2016" href="#footnote-He2016">[He2016]</a></sup>, although here we don&#39;t perform any further subdivision   of the permutation patterns (as in Figure 3 of<sup class="footnote-reference"><a id="citeref-He2016" href="#footnote-He2016">[He2016]</a></sup>).</li></ul><p>Internally, <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> uses the <a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a> to represent ordinal patterns as integers for efficient computations.</p><p>See <a href="#ComplexityMeasures.WeightedOrdinalPatterns"><code>WeightedOrdinalPatterns</code></a> and <a href="#ComplexityMeasures.AmplitudeAwareOrdinalPatterns"><code>AmplitudeAwareOrdinalPatterns</code></a> for estimators that not only consider ordinal (sorting) patterns, but also incorporate information about within-state-vector amplitudes. For a version of this estimator that can be used on spatial data, see <a href="#ComplexityMeasures.SpatialOrdinalPatterns"><code>SpatialOrdinalPatterns</code></a>.</p><div class="admonition is-info"><header class="admonition-header">Handling equal values in ordinal patterns</header><div class="admonition-body"><p>In Bandt &amp; Pompe (2002), equal values are ordered after their order of appearance, but this can lead to erroneous temporal correlations, especially for data with low amplitude resolution <sup class="footnote-reference"><a id="citeref-Zunino2017" href="#footnote-Zunino2017">[Zunino2017]</a></sup>. Here, by default, if two values are equal, then one of the is randomly assigned as &quot;the largest&quot;, using <code>lt = ComplexityMeasures.isless_rand</code>. To get the behaviour from Bandt and Pompe (2002), use <code>lt = Base.isless</code>.</p></div></div><p><strong>Outcome space</strong></p><p>The outcome space <code>Ω</code> for <code>OrdinalPatterns</code> is the set of length-<code>m</code> ordinal patterns (i.e. permutations) that can be formed by the integers <code>1, 2, …, m</code>. There are <code>factorial(m)</code> such patterns.</p><p>For example, the outcome <code>[2, 3, 1]</code> corresponds to the ordinal pattern of having the smallest value in the second position, the next smallest value in the third position, and the next smallest, i.e. the largest value in the first position. See also [<code>OrdinalPatternEncoding</code>(@ref).</p><p><strong>In-place symbolization</strong></p><p><code>OrdinalPatterns</code> also implements the in-place <a href="#ComplexityMeasures.probabilities!"><code>probabilities!</code></a> for <code>StateSpaceSet</code> input (or embedded vector input) for reducing allocations in looping scenarios. The length of the pre-allocated symbol vector must be the length of the dataset. For example</p><pre><code class="language-julia hljs">using ComplexityMeasures
m, N = 2, 100
est = OrdinalPatterns(; m, τ)
x = StateSpaceSet(rand(N, m)) # some input dataset
πs_ts = zeros(Int, N) # length must match length of `x`
p = probabilities!(πs_ts, est, x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/symbolic_permutation.jl#L21-L99">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.WeightedOrdinalPatterns" href="#ComplexityMeasures.WeightedOrdinalPatterns"><code>ComplexityMeasures.WeightedOrdinalPatterns</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WeightedOrdinalPatterns &lt;: OutcomeSpace
WeightedOrdinalPatterns(; τ = 1, m = 3, lt::Function = ComplexityMeasures.isless_rand)</code></pre><p>A variant of <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> that also incorporates amplitude information, based on the weighted permutation entropy<sup class="footnote-reference"><a id="citeref-Fadlallah2013" href="#footnote-Fadlallah2013">[Fadlallah2013]</a></sup>. The outcome space and keywords are the same as in <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>.</p><p><strong>Description</strong></p><p>For each ordinal pattern extracted from each state (or delay) vector, a weight is attached to it which is the variance of the vector. Probabilities are then estimated by summing the weights corresponding to the same pattern, instead of just counting the occurrence of the same pattern.</p><div class="admonition is-info"><header class="admonition-header">An implementation note</header><div class="admonition-body"><p><em>Note: in equation 7, section III, of the original paper, the authors write</em></p><p class="math-container">\[w_j = \dfrac{1}{m}\sum_{k=1}^m (x_{j-(k-1)\tau} - \mathbf{\hat{x}}_j^{m, \tau})^2.\]</p><p>*But given the formula they give for the arithmetic mean, this is <strong>not</strong> the variance of the delay vector <span>$\mathbf{x}_i$</span>, because the indices are mixed: <span>$x_{j+(k-1)\tau}$</span> in the weights formula, vs. <span>$x_{j+(k+1)\tau}$</span> in the arithmetic mean formula. Here, delay embedding and computation of the patterns and their weights are completely separated processes, ensuring that we compute the arithmetic mean correctly for each vector of the input dataset (which may be a delay-embedded timeseries).</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/symbolic_permutation.jl#L105-L138">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.AmplitudeAwareOrdinalPatterns" href="#ComplexityMeasures.AmplitudeAwareOrdinalPatterns"><code>ComplexityMeasures.AmplitudeAwareOrdinalPatterns</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AmplitudeAwareOrdinalPatterns &lt;: OutcomeSpace
AmplitudeAwareOrdinalPatterns(; τ = 1, m = 3, A = 0.5, lt = ComplexityMeasures.isless_rand)</code></pre><p>A variant of <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> that also incorporates amplitude information, based on the amplitude-aware permutation entropy<sup class="footnote-reference"><a id="citeref-Azami2016" href="#footnote-Azami2016">[Azami2016]</a></sup>. The outcome space and keywords are the same as in <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>.</p><p><strong>Description</strong></p><p>Similarly to <a href="#ComplexityMeasures.WeightedOrdinalPatterns"><code>WeightedOrdinalPatterns</code></a>, a weight <span>$w_i$</span> is attached to each ordinal pattern extracted from each state (or delay) vector <span>$\mathbf{x}_i = (x_1^i, x_2^i, \ldots, x_m^i)$</span> as</p><p class="math-container">\[w_i = \dfrac{A}{m} \sum_{k=1}^m |x_k^i | + \dfrac{1-A}{d-1}
\sum_{k=2}^d |x_{k}^i - x_{k-1}^i|,\]</p><p>with <span>$0 \leq A \leq 1$</span>. When <span>$A=0$</span> , only internal differences between the elements of <span>$\mathbf{x}_i$</span> are weighted. Only mean amplitude of the state vector elements are weighted when <span>$A=1$</span>. With, <span>$0&lt;A&lt;1$</span>, a combined weighting is used.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/symbolic_permutation.jl#L146-L173">source</a></section></article><h3 id="Dispersion-patterns"><a class="docs-heading-anchor" href="#Dispersion-patterns">Dispersion patterns</a><a id="Dispersion-patterns-1"></a><a class="docs-heading-anchor-permalink" href="#Dispersion-patterns" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.Dispersion" href="#ComplexityMeasures.Dispersion"><code>ComplexityMeasures.Dispersion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Dispersion(; c = 5, m = 2, τ = 1, check_unique = true)</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on dispersion patterns, originally used by Rostaghi &amp; Azami, 2016<sup class="footnote-reference"><a id="citeref-Rostaghi2016" href="#footnote-Rostaghi2016">[Rostaghi2016]</a></sup> to compute the &quot;dispersion entropy&quot;, which characterizes the complexity and irregularity of a time series.</p><p>Recommended parameter values<sup class="footnote-reference"><a id="citeref-Li2018" href="#footnote-Li2018">[Li2018]</a></sup> are <code>m ∈ [2, 3]</code>, <code>τ = 1</code> for the embedding, and <code>c ∈ [3, 4, …, 8]</code> categories for the Gaussian symbol mapping.</p><p><strong>Description</strong></p><p>Assume we have a univariate time series <span>$X = \{x_i\}_{i=1}^N$</span>. First, this time series is encoded into a symbol timeseries <span>$S$</span> using the Gaussian encoding <a href="#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a> with empirical mean <code>μ</code> and empirical standard deviation <code>σ</code> (both determined from <span>$X$</span>), and <code>c</code> as given to <code>Dispersion</code>.</p><p>Then, <span>$S$</span> is embedded into an <span>$m$</span>-dimensional time series, using an embedding lag of <span>$\tau$</span>, which yields a total of <span>$N - (m - 1)\tau$</span> delay vectors <span>$z_i$</span>, or &quot;dispersion patterns&quot;. Since each element of <span>$z_i$</span> can take on <code>c</code> different values, and each delay vector has <code>m</code> entries, there are <code>c^m</code> possible dispersion patterns. This number is used for normalization when computing dispersion entropy.</p><p>The returned probabilities are simply the frequencies of the unique dispersion patterns present in <span>$S$</span> (i.e., the <a href="@ref"><code>CountOccurences</code></a> of <span>$S$</span>).</p><p><strong>Outcome space</strong></p><p>The outcome space for <code>Dispersion</code> is the unique delay vectors whose elements are the the symbols (integers) encoded by the Gaussian CDF, i.e., the unique elements of <span>$S$</span>.</p><p><strong>Data requirements and parameters</strong></p><p>The input must have more than one unique element for the Gaussian mapping to be well-defined. Li et al. (2018) recommends that <code>x</code> has at least 1000 data points.</p><p>If <code>check_unique == true</code> (default), then it is checked that the input has more than one unique value. If <code>check_unique == false</code> and the input only has one unique element, then a <code>InexactError</code> is thrown when trying to compute probabilities.</p><div class="admonition is-info"><header class="admonition-header">Why &#39;dispersion patterns&#39;?</header><div class="admonition-body"><p>Each embedding vector is called a &quot;dispersion pattern&quot;. Why? Let&#39;s consider the case when <span>$m = 5$</span> and <span>$c = 3$</span>, and use some very imprecise terminology for illustration:</p><p>When <span>$c = 3$</span>, values clustering far below mean are in one group, values clustered around the mean are in one group, and values clustering far above the mean are in a third group. Then the embedding vector <span>$[2, 2, 2, 2, 2]$</span> consists of values that are close together (close to the mean), so it represents a set of numbers that are not very spread out (less dispersed). The embedding vector <span>$[1, 1, 2, 3, 3]$</span>, however, represents numbers that are much more spread out (more dispersed), because the categories representing &quot;outliers&quot; both above and below the mean are represented, not only values close to the mean.</p></div></div><p>For a version of this estimator that can be used on high-dimensional arrays, see <a href="#ComplexityMeasures.SpatialDispersion"><code>SpatialDispersion</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/dispersion.jl#L5-L70">source</a></section></article><h3 id="Transfer-operator"><a class="docs-heading-anchor" href="#Transfer-operator">Transfer operator</a><a id="Transfer-operator-1"></a><a class="docs-heading-anchor-permalink" href="#Transfer-operator" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.TransferOperator" href="#ComplexityMeasures.TransferOperator"><code>ComplexityMeasures.TransferOperator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TransferOperator &lt;: OutcomeSpace
TransferOperator(b::AbstractBinning)</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on binning data into rectangular boxes dictated by the given binning scheme <code>b</code>.</p><p>When used with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>, then the transfer (Perron-Frobenius) operator is approximated over the bins, then bin probabilities are estimated as the invariant measure associated with that transfer operator. Assumes that the input data are sequential (time-ordered).</p><p>This implementation follows the grid estimator approach in Diego et al. (2019)<sup class="footnote-reference"><a id="citeref-Diego2019" href="#footnote-Diego2019">[Diego2019]</a></sup>.</p><p><strong>Outcome space</strong></p><p>The outcome space for <code>TransferOperator</code> is the set of unique bins constructed from <code>b</code>. Bins are identified by their left (lowest-value) corners, are given in data units, and are returned as <code>SVector</code>s.</p><p><strong>Bin ordering</strong></p><p>Bins returned by <a href="#ComplexityMeasures.probabilities_and_outcomes"><code>probabilities_and_outcomes</code></a> are ordered according to first appearance (i.e. the first time the input (multivariate) timeseries visits the bin). Thus, if</p><pre><code class="language-julia hljs">b = RectangularBinning(4)
est = TransferOperator(b)
probs, outcomes = probabilities_and_outcomes(x, est) # x is some timeseries</code></pre><p>then <code>probs[i]</code> is the invariant measure (probability) of the bin <code>outcomes[i]</code>, which is the <code>i</code>-th bin visited by the timeseries with nonzero measure.</p><p><strong>Description</strong></p><p>The transfer operator <span>$P^{N}$</span>is computed as an <code>N</code>-by-<code>N</code> matrix of transition probabilities between the states defined by the partition elements, where <code>N</code> is the number of boxes in the partition that is visited by the orbit/points.</p><p>If  <span>$\{x_t^{(D)} \}_{n=1}^L$</span> are the <span>$L$</span> different <span>$D$</span>-dimensional points over which the transfer operator is approximated, <span>$\{ C_{k=1}^N \}$</span> are the <span>$N$</span> different partition elements (as dictated by <code>ϵ</code>) that gets visited by the points, and  <span>$\phi(x_t) = x_{t+1}$</span>, then</p><p class="math-container">\[P_{ij} = \dfrac
{\#\{ x_n | \phi(x_n) \in C_j \cap x_n \in C_i \}}
{\#\{ x_m | x_m \in C_i \}},\]</p><p>where <span>$\#$</span> denotes the cardinal. The element <span>$P_{ij}$</span> thus indicates how many points that are initially in box <span>$C_i$</span> end up in box <span>$C_j$</span> when the points in <span>$C_i$</span> are projected one step forward in time. Thus, the row <span>$P_{ik}^N$</span> where <span>$k \in \{1, 2, \ldots, N \}$</span> gives the probability of jumping from the state defined by box <span>$C_i$</span> to any of the other <span>$N$</span> states. It follows that <span>$\sum_{k=1}^{N} P_{ik} = 1$</span> for all <span>$i$</span>. Thus, <span>$P^N$</span> is a row/right stochastic matrix.</p><p><strong>Invariant measure estimation from transfer operator</strong></p><p>The left invariant distribution <span>$\mathbf{\rho}^N$</span> is a row vector, where <span>$\mathbf{\rho}^N P^{N} = \mathbf{\rho}^N$</span>. Hence, <span>$\mathbf{\rho}^N$</span> is a row eigenvector of the transfer matrix <span>$P^{N}$</span> associated with eigenvalue 1. The distribution <span>$\mathbf{\rho}^N$</span> approximates the invariant density of the system subject to <code>binning</code>, and can be taken as a probability distribution over the partition elements.</p><p>In practice, the invariant measure <span>$\mathbf{\rho}^N$</span> is computed using <a href="#ComplexityMeasures.invariantmeasure"><code>invariantmeasure</code></a>, which also approximates the transfer matrix. The invariant distribution is initialized as a length-<code>N</code> random distribution which is then applied to <span>$P^{N}$</span>. The resulting length-<code>N</code> distribution is then applied to <span>$P^{N}$</span> again. This process repeats until the difference between the distributions over consecutive iterations is below some threshold.</p><p>See also: <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a>, <a href="#ComplexityMeasures.invariantmeasure"><code>invariantmeasure</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/transfer_operator/transfer_operator.jl#L11-L92">source</a></section></article><h4 id="Utility-methods/types"><a class="docs-heading-anchor" href="#Utility-methods/types">Utility methods/types</a><a id="Utility-methods/types-1"></a><a class="docs-heading-anchor-permalink" href="#Utility-methods/types" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.InvariantMeasure" href="#ComplexityMeasures.InvariantMeasure"><code>ComplexityMeasures.InvariantMeasure</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InvariantMeasure(to, ρ)</code></pre><p>Minimal return struct for <a href="#ComplexityMeasures.invariantmeasure"><code>invariantmeasure</code></a> that contains the estimated invariant measure <code>ρ</code>, as well as the transfer operator <code>to</code> from which it is computed (including bin information).</p><p>See also: <a href="#ComplexityMeasures.invariantmeasure"><code>invariantmeasure</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/transfer_operator/transfer_operator.jl#L295-L303">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.invariantmeasure" href="#ComplexityMeasures.invariantmeasure"><code>ComplexityMeasures.invariantmeasure</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">invariantmeasure(x::AbstractStateSpaceSet, binning::RectangularBinning) → iv::InvariantMeasure</code></pre><p>Estimate an invariant measure over the points in <code>x</code> based on binning the data into rectangular boxes dictated by the <code>binning</code>, then approximate the transfer (Perron-Frobenius) operator over the bins. From the approximation to the transfer operator, compute an invariant distribution over the bins. Assumes that the input data are sequential.</p><p>Details on the estimation procedure is found the <a href="#ComplexityMeasures.TransferOperator"><code>TransferOperator</code></a> docstring.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">using DynamicalSystems
henon_rule(x, p, n) = SVector{2}(1.0 - p[1]*x[1]^2 + x[2], p[2]*x[1])
henon = DeterministicIteratedMap(henon_rule, zeros(2), [1.4, 0.3])
orbit, t = trajectory(ds, 20_000; Ttr = 10)

# Estimate the invariant measure over some coarse graining of the orbit.
iv = invariantmeasure(orbit, RectangularBinning(15))

# Get the probabilities and bins
invariantmeasure(iv)</code></pre><p><strong>Probabilities and bin information</strong></p><pre><code class="nohighlight hljs">invariantmeasure(iv::InvariantMeasure) → (ρ::Probabilities, bins::Vector{&lt;:SVector})</code></pre><p>From a pre-computed invariant measure, return the probabilities and associated bins. The element <code>ρ[i]</code> is the probability of visitation to the box <code>bins[i]</code>. Analogous to <a href="@ref"><code>binhist</code></a>.</p><div class="admonition is-category-hint"><header class="admonition-header">Transfer operator approach vs. naive histogram approach</header><div class="admonition-body"><p>Why bother with the transfer operator instead of using regular histograms to obtain probabilities?</p><p>In fact, the naive histogram approach and the transfer operator approach are equivalent in the limit of long enough time series (as <span>$n \to \intfy$</span>), which is guaranteed by the ergodic theorem. There is a crucial difference, however:</p><p>The naive histogram approach only gives the long-term probabilities that orbits visit a certain region of the state space. The transfer operator encodes that information too, but comes with the added benefit of knowing the <em>transition probabilities</em> between states (see <a href="#ComplexityMeasures.transfermatrix"><code>transfermatrix</code></a>).</p></div></div><p>See also: <a href="#ComplexityMeasures.InvariantMeasure"><code>InvariantMeasure</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/transfer_operator/transfer_operator.jl#L316-L366">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.transfermatrix" href="#ComplexityMeasures.transfermatrix"><code>ComplexityMeasures.transfermatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">transfermatrix(iv::InvariantMeasure) → (M::AbstractArray{&lt;:Real, 2}, bins::Vector{&lt;:SVector})</code></pre><p>Return the transfer matrix/operator and corresponding bins. Here, <code>bins[i]</code> corresponds to the i-th row/column of the transfer matrix. Thus, the entry <code>M[i, j]</code> is the probability of jumping from the state defined by <code>bins[i]</code> to the state defined by <code>bins[j]</code>.</p><p>See also: <a href="#ComplexityMeasures.TransferOperator"><code>TransferOperator</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/transfer_operator/transfer_operator.jl#L434-L443">source</a></section></article><h3 id="Kernel-density"><a class="docs-heading-anchor" href="#Kernel-density">Kernel density</a><a id="Kernel-density-1"></a><a class="docs-heading-anchor-permalink" href="#Kernel-density" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.NaiveKernel" href="#ComplexityMeasures.NaiveKernel"><code>ComplexityMeasures.NaiveKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NaiveKernel(ϵ::Real; method = KDTree, w = 0, metric = Euclidean()) &lt;: OutcomeSpace</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on a &quot;naive&quot; kernel density estimation approach (KDE), as discussed in Prichard and Theiler (1995) <sup class="footnote-reference"><a id="citeref-PrichardTheiler1995" href="#footnote-PrichardTheiler1995">[PrichardTheiler1995]</a></sup>.</p><p>Probabilities <span>$P(\mathbf{x}, \epsilon)$</span> are assigned to every point <span>$\mathbf{x}$</span> by counting how many other points occupy the space spanned by a hypersphere of radius <code>ϵ</code> around <span>$\mathbf{x}$</span>, according to:</p><p class="math-container">\[P_i( X, \epsilon) \approx \dfrac{1}{N} \sum_{s} B(||X_i - X_j|| &lt; \epsilon),\]</p><p>where <span>$B$</span> gives 1 if the argument is <code>true</code>. Probabilities are then normalized.</p><p><strong>Keyword arguments</strong></p><ul><li><code>method = KDTree</code>: the search structure supported by Neighborhood.jl. Specifically, use <code>KDTree</code> to use a tree-based neighbor search, or <code>BruteForce</code> for the direct distances between all points. KDTrees heavily outperform direct distances when the dimensionality of the data is much smaller than the data length.</li><li><code>w = 0</code>: the Theiler window, which excludes indices <span>$s$</span> that are within <span>$|i - s| ≤ w$</span> from the given point <span>$x_i$</span>.</li><li><code>metric = Euclidean()</code>: the distance metric.</li></ul><p><strong>Outcome space</strong></p><p>The outcome space <code>Ω</code> for <code>NaiveKernel</code> are the indices of the input data, <code>eachindex(x)</code>. Hence, input <code>x</code> is needed for a well-defined <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a>. The reason to not return the data points themselves is because duplicate data points may not get assigned same probabilities (due to having different neighbors).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/kernel_density.jl#L5-L41">source</a></section></article><h3 id="Timescales"><a class="docs-heading-anchor" href="#Timescales">Timescales</a><a id="Timescales-1"></a><a class="docs-heading-anchor-permalink" href="#Timescales" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.WaveletOverlap" href="#ComplexityMeasures.WaveletOverlap"><code>ComplexityMeasures.WaveletOverlap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">WaveletOverlap([wavelet]) &lt;: OutcomeSpace</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on the maximal overlap discrete wavelet transform (MODWT).</p><p>When used with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>, the MODWT is applied to a signal, then probabilities are computed as the (normalized) energies at different wavelet scales. These probabilities are used to compute the wavelet entropy, according to Rosso et al. (2001)<sup class="footnote-reference"><a id="citeref-Rosso2001" href="#footnote-Rosso2001">[Rosso2001]</a></sup>. Input timeseries <code>x</code> is needed for a well-defined outcome space.</p><p>By default the wavelet <code>Wavelets.WT.Daubechies{12}()</code> is used. Otherwise, you may choose a wavelet from the <code>Wavelets</code> package (it must subtype <code>OrthoWaveletClass</code>).</p><p><strong>Outcome space</strong></p><p>The outcome space for <code>WaveletOverlap</code> are the integers <code>1, 2, …, N</code> enumerating the wavelet scales. To obtain a better understanding of what these mean, we prepared a notebook you can <a href="https://github.com/kahaaga/waveletentropy_example/blob/main/wavelet_entropy_example.ipynb">view online</a>. As such, this estimator only works for timeseries input and input <code>x</code> is needed for a well-defined <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/wavelet_overlap.jl#L4-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.PowerSpectrum" href="#ComplexityMeasures.PowerSpectrum"><code>ComplexityMeasures.PowerSpectrum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PowerSpectrum() &lt;: OutcomeSpace</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on the power spectrum of a timeseries (amplitude square of its Fourier transform).</p><p>If used with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>, then the spectrum normalized to sum = 1 is returned as probabilities. The Shannon entropy of these probabilities is typically referred in the literature as <em>spectral entropy</em>, e.g. <sup class="footnote-reference"><a id="citeref-Llanos2016" href="#footnote-Llanos2016">[Llanos2016]</a></sup>,<sup class="footnote-reference"><a id="citeref-Tian2017" href="#footnote-Tian2017">[Tian2017]</a></sup>.</p><p>The closer the spectrum is to flat, i.e., white noise, the higher the entropy. However, you can&#39;t compare entropies of timeseries with different length, because the binning in spectral space depends on the length of the input.</p><p><strong>Outcome space</strong></p><p>The outcome space <code>Ω</code> for <code>PowerSpectrum</code> is the set of frequencies in Fourier space. They should be multiplied with the sampling rate of the signal, which is assumed to be <code>1</code>. Input <code>x</code> is needed for a well-defined <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/power_spectrum.jl#L4-L34">source</a></section></article><h3 id="Diversity"><a class="docs-heading-anchor" href="#Diversity">Diversity</a><a id="Diversity-1"></a><a class="docs-heading-anchor-permalink" href="#Diversity" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.Diversity" href="#ComplexityMeasures.Diversity"><code>ComplexityMeasures.Diversity</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Diversity(; m::Int, τ::Int, nbins::Int)</code></pre><p>A <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on the cosine similarity. It can be used with <a href="../information_measures/#ComplexityMeasures.information-Tuple{InformationMeasure, OutcomeSpace, Any}"><code>information</code></a> to compute the diversity entropy of an input timeseries<sup class="footnote-reference"><a id="citeref-Wang2020" href="#footnote-Wang2020">[Wang2020]</a></sup>.</p><p>The implementation here allows for <code>τ != 1</code>, which was not considered in the original paper.</p><p><strong>Description</strong></p><p>Diversity probabilities are computed as follows.</p><ol><li>From the input time series <code>x</code>, using embedding lag <code>τ</code> and embedding dimension <code>m</code>,  construct the embedding  <span>$Y = \{\bf x_i \} = \{(x_{i}, x_{i+\tau}, x_{i+2\tau}, \ldots, x_{i+m\tau - 1}\}_{i = 1}^{N-mτ}$</span>.</li><li>Compute <span>$D = \{d(\bf x_t, \bf x_{t+1}) \}_{t=1}^{N-mτ-1}$</span>,  where <span>$d(\cdot, \cdot)$</span> is the cosine similarity between two <code>m</code>-dimensional  vectors in the embedding.</li><li>Divide the interval <code>[-1, 1]</code> into <code>nbins</code> equally sized subintervals (including the value <code>+1</code>).</li><li>Construct a histogram of cosine similarities <span>$d \in D$</span> over those subintervals.</li><li>Sum-normalize the histogram to obtain probabilities.</li></ol><p><strong>Outcome space</strong></p><p>The outcome space for <code>Diversity</code> is the bins of the <code>[-1, 1]</code> interval, and the return configuration is the same as in <a href="#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a> (left bin edge).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/diversity.jl#L5-L37">source</a></section></article><h3 id="Spatial-outcome-spaces"><a class="docs-heading-anchor" href="#Spatial-outcome-spaces">Spatial outcome spaces</a><a id="Spatial-outcome-spaces-1"></a><a class="docs-heading-anchor-permalink" href="#Spatial-outcome-spaces" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.SpatialOrdinalPatterns" href="#ComplexityMeasures.SpatialOrdinalPatterns"><code>ComplexityMeasures.SpatialOrdinalPatterns</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SpatialOrdinalPatterns &lt;: OutcomeSpaceModel
SpatialOrdinalPatterns(stencil, x; periodic = true)</code></pre><p>A symbolic, permutation-based <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> for spatiotemporal systems that generalises <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> to high-dimensional arrays. The order <code>m</code> of the permutation pattern is extracted from the <code>stencil</code>, see below.</p><p><code>SpatialOrdinalPatterns</code> is based on the 2D and 3D <em>spatiotemporal permutation entropy</em> estimators by by Ribeiro et al. (2012)<sup class="footnote-reference"><a id="citeref-Ribeiro2012" href="#footnote-Ribeiro2012">[Ribeiro2012]</a></sup> and Schlemmer et al. (2018)<sup class="footnote-reference"><a id="citeref-Schlemmer2018" href="#footnote-Schlemmer2018">[Schlemmer2018]</a></sup>), respectively, but is here implemented as a pure probabilities probabilities estimator that is generalized for <code>D</code>-dimensional input array <code>x</code>, with arbitrary regions (stencils) to get patterns form and (possibly) periodic boundary conditions.</p><p>See below for ways to specify the <code>stencil</code>. If <code>periodic = true</code>, then the stencil wraps around at the ends of the array. If <code>false</code>, then collected regions with indices which exceed the array bounds are skipped.</p><p>In combination with <a href="../information_measures/#ComplexityMeasures.information-Tuple{InformationMeasure, OutcomeSpace, Any}"><code>information</code></a> and <a href="../information_measures/#ComplexityMeasures.information_normalized"><code>information_normalized</code></a>, this probabilities estimator can be used to compute generalized spatiotemporal permutation <a href="../information_measures/#ComplexityMeasures.InformationMeasure"><code>InformationMeasure</code></a> of any type.</p><p><strong>Outcome space</strong></p><p>The outcome space <code>Ω</code> for <code>SpatialOrdinalPatterns</code> is the set of length-<code>m</code> ordinal patterns (i.e. permutations) that can be formed by the integers <code>1, 2, …, m</code>, ordered lexicographically. There are <code>factorial(m)</code> such patterns. Here <code>m</code> refers to the number of points included in <code>stencil</code>.</p><p><strong>Stencils</strong></p><p>The <code>stencil</code> defines what local area to use to group hypervoxels. Each grouping of hypervoxels is mapped to an order-<code>m</code> permutation pattern, which is then mapped to an integer as in <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>. The <code>stencil</code> is moved around the input array, in a sense &quot;scanning&quot; the input array, to collect all possible groupings allowed by the boundary condition (periodic or not).</p><p>Stencils are passed in one of the following three ways:</p><ol><li>As vectors of <code>CartesianIndex</code> which encode the offset of indices to include in the  stencil, with respect to the current array index when scanning over the array.  For example <code>stencil = CartesianIndex.([(0,0), (0,1), (1,1), (1,0)])</code>.  Don&#39;t forget to include the zero offset index if you want to include the hypervoxel  itself, which is almost always the case.  Here the stencil creates a 2x2 square extending to the bottom and right of the pixel  (directions here correspond to the way Julia prints matrices by default).  When passing a stencil as a vector of <code>CartesianIndex</code>, <code>m = length(stencil)</code>.</li><li>As a <code>D</code>-dimensional array (where <code>D</code> matches the dimensionality of the input data)  containing <code>0</code>s and <code>1</code>s, where if <code>stencil[index] == 1</code>, the corresponding pixel is  included, and if <code>stencil[index] == 0</code>, it is not included.  To generate the same estimator as in 1., use <code>stencil = [1 1; 1 1]</code>.  When passing a stencil as a <code>D</code>-dimensional array, <code>m = sum(stencil)</code></li><li>As a <code>Tuple</code> containing two <code>Tuple</code>s, both of length <code>D</code>, for <code>D</code>-dimensional data.  The first tuple specifies the <code>extent</code> of the stencil, where <code>extent[i]</code>  dictates the number of hypervoxels to be included along the <code>i</code>th axis and <code>lag[i]</code>  the separation of hypervoxels along the same axis.  This method can only generate (hyper)rectangular stencils. To create the same estimator as  in the previous examples, use here <code>stencil = ((2, 2), (1, 1))</code>.  When passing a stencil using <code>extent</code> and <code>lag</code>, <code>m = prod(extent)</code>.</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/spatial/spatial_ordinal/SpatialOrdinalPatterns.jl#L8-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.SpatialDispersion" href="#ComplexityMeasures.SpatialDispersion"><code>ComplexityMeasures.SpatialDispersion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SpatialDispersion &lt;: OutcomeSpace
SpatialDispersion(stencil, x::AbstractArray;
    periodic = true,
    c = 5,
    skip_encoding = false,
    L = nothing,
)</code></pre><p>A dispersion-based <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> that generalises <a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a> for input data that are high-dimensional arrays.</p><p><code>SpatialDispersion</code> is based on Azami et al. (2019)<sup class="footnote-reference"><a id="citeref-Azami2019" href="#footnote-Azami2019">[Azami2019]</a></sup>&#39;s 2D square dispersion (Shannon) entropy estimator, but is here implemented as a pure probabilities probabilities estimator that is generalized for <code>N</code>-dimensional input data <code>x</code>, with arbitrary neighborhood regions (stencils) and (optionally) periodic boundary conditions.</p><p>In combination with <a href="../information_measures/#ComplexityMeasures.information-Tuple{InformationMeasure, OutcomeSpace, Any}"><code>information</code></a> and <a href="../information_measures/#ComplexityMeasures.information_normalized"><code>information_normalized</code></a>, this probabilities estimator can be used to compute (normalized) generalized spatiotemporal dispersion <a href="../information_measures/#ComplexityMeasures.InformationMeasure"><code>InformationMeasure</code></a> of any type.</p><p><strong>Arguments</strong></p><ul><li><code>stencil</code>. Defines what local area (hyperrectangle), or which points within this area,   to include around each hypervoxel (i.e. pixel in 2D). The examples below demonstrate   different ways of specifying stencils. For details, see   <a href="#ComplexityMeasures.SpatialOrdinalPatterns"><code>SpatialOrdinalPatterns</code></a>. See <a href="#ComplexityMeasures.SpatialOrdinalPatterns"><code>SpatialOrdinalPatterns</code></a> for   more information about stencils.</li><li><code>x::AbstractArray</code>. The input data. Must be provided because we need to know its size   for optimization and bound checking.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>periodic::Bool</code>. If <code>periodic == true</code>, then the stencil should wrap around at the   end of the array. If <code>periodic = false</code>, then pixels whose stencil exceeds the array   bounds are skipped.</li><li><code>c::Int</code>. Determines how many discrete categories to use for the Gaussian encoding.</li><li><code>skip_encoding</code>. If <code>skip_encoding == true</code>, <code>encoding</code> is ignored, and dispersion   patterns are computed directly from <code>x</code>, under the assumption that <code>L</code> is the alphabet   length for <code>x</code> (useful for categorical or integer data). Thus, if   <code>skip_encoding == true</code>, then <code>L</code> must also be specified. This is useful for   categorical or integer-valued data.</li><li><code>L</code>. If <code>L == nothing</code> (default), then the number of total outcomes is inferred from   <code>stencil</code> and <code>encoding</code>. If <code>L</code> is set to an integer, then the data is considered   pre-encoded and the number of total outcomes is set to <code>L</code>.</li></ul><p><strong>Outcome space</strong></p><p>The outcome space for <code>SpatialDispersion</code> is the unique delay vectors whose elements are the the symbols (integers) encoded by the Gaussian CDF. Hence, the outcome space is all <code>m</code>-dimensional delay vectors whose elements are all possible values in <code>1:c</code>. There are <code>c^m</code> such vectors.</p><p><strong>Description</strong></p><p>Estimating probabilities/entropies from higher-dimensional data is conceptually simple.</p><ol><li>Discretize each value (hypervoxel) in <code>x</code> relative to all other values <code>xᵢ ∈ x</code> using the  provided <code>encoding</code> scheme.</li><li>Use <code>stencil</code> to extract relevant (discretized) points around each hypervoxel.</li><li>Construct a symbol these points.</li><li>Take the sum-normalized histogram of the symbol as a probability distribution.</li><li>Optionally, compute <a href="../information_measures/#ComplexityMeasures.information-Tuple{InformationMeasure, OutcomeSpace, Any}"><code>information</code></a> or <a href="../information_measures/#ComplexityMeasures.information_normalized"><code>information_normalized</code></a> from this  probability distribution.</li></ol><p><strong>Usage</strong></p><p>Here&#39;s how to compute spatial dispersion entropy using the three different ways of specifying stencils.</p><pre><code class="language-julia hljs">x = rand(50, 50) # first &quot;time slice&quot; of a spatial system evolution

# Cartesian stencil
stencil_cartesian = CartesianIndex.([(0,0), (1,0), (1,1), (0,1)])
est = SpatialDispersion(stencil_cartesian, x)
information_normalized(est, x)

# Extent/lag stencil
extent = (2, 2); lag = (1, 1); stencil_ext_lag = (extent, lag)
est = SpatialDispersion(stencil_ext_lag, x)
information_normalized(est, x)

# Matrix stencil
stencil_matrix = [1 1; 1 1]
est = SpatialDispersion(stencil_matrix, x)
information_normalized(est, x)</code></pre><p>To apply this to timeseries of spatial data, simply loop over the call (broadcast), e.g.:</p><pre><code class="language-julia hljs">imgs = [rand(50, 50) for i = 1:100]; # one image per second over 100 seconds
stencil = ((2, 2), (1, 1)) # a 2x2 stencil (i.e. dispersion patterns of length 4)
est = SpatialDispersion(stencil, first(imgs))
h_vs_t = information_normalized.(Ref(est), imgs)</code></pre><p>Computing generalized spatiotemporal dispersion entropy is trivial, e.g. with <a href="../information_measures/#ComplexityMeasures.Renyi"><code>Renyi</code></a>:</p><pre><code class="language-julia hljs">x = reshape(repeat(1:5, 500) .+ 0.1*rand(500*5), 50, 50)
est = SpatialDispersion(stencil, x)
information(Renyi(q = 2), est, x)</code></pre><p>See also: <a href="#ComplexityMeasures.SpatialOrdinalPatterns"><code>SpatialOrdinalPatterns</code></a>, <a href="#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a>, <a href="@ref"><code>symbolize</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/outcome_spaces/spatial/spatial_dispersion/SpatialDispersion.jl#L5-L120">source</a></section></article><h2 id="Probabilities"><a class="docs-heading-anchor" href="#Probabilities">Probabilities</a><a id="Probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilities" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.Probabilities" href="#ComplexityMeasures.Probabilities"><code>ComplexityMeasures.Probabilities</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Probabilities &lt;: AbstractArray
Probabilities(x) → p</code></pre><p><code>Probabilities</code> is a simple wrapper around <code>x::AbstractArray{&lt;:Real, N}</code> that ensures its values sum to 1, so that <code>p</code> can be interpreted as <code>N</code>-dimensional probability mass function. In most use cases, <code>p</code> will be a vector. <code>p</code> behaves exactly like its contained data <code>x</code> with respect to indexing and iteration.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L11-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.probabilities" href="#ComplexityMeasures.probabilities"><code>ComplexityMeasures.probabilities</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">probabilities(o::OutcomeSpace, x::Array_or_SSSet) → p::Probabilities
probabilities(est::ProbabilitiesEstimator, x::Array_or_SSSet) → p::Probabilities</code></pre><p>Compute a probability distribution over the set of possible outcomes defined by the <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> <code>o</code>, given input data <code>x</code>, using maximum likelihood probability estimation (<a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a>).</p><p>To use some other form of probabilities estimation than <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a>, use the second signature. In this case, the outcome space is given as the first argument to a <a href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a>. Note that this only works for counting-based outcome spaces (see <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>&#39;s docstring for list of compatible outcome spaces).</p><p>The input data is typically an <code>Array</code> or a <code>StateSpaceSet</code> (or <code>SSSet</code> for sort); see <a href="@ref">Input data for ComplexityMeasures.jl</a>. Configuration options are always given as arguments to the chosen outcome space.</p><p>To obtain the outcomes corresponding to the probabilities <code>p</code>, use <a href="#ComplexityMeasures.outcomes"><code>outcomes</code></a>, or <a href="#ComplexityMeasures.probabilities_and_outcomes"><code>probabilities_and_outcomes</code></a>, which return both the probabilities and the outcomes together.</p><p>Due to performance optimizations, whether the returned probabilities contain <code>0</code>s as entries or not depends on the outcome space. E.g., in <a href="#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a> <code>0</code>s are skipped, while in <a href="#ComplexityMeasures.PowerSpectrum"><code>PowerSpectrum</code></a> <code>0</code> are not, because we get them for free. Use <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>/<a href="#ComplexityMeasures.allprobabilities_and_outcomes"><code>allprobabilities_and_outcomes</code></a> to guarantee that zero probabilities are also returned (may be slower).</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">x = randn(500)
ps = probabilities(OrdinalPatterns(m = 3), x)
ps = probabilities(ValueHistogram(RectangularBinning(5)), x)
ps = probabilities(WaveletOverlap(), x)</code></pre><p>The outcome space is here given as the first argument to <code>est</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">x = randn(500)

# Syntactically equivalent to `probabilities(OrdinalPatterns(m = 3), x)`
ps = probabilities(RelativeAmount(OrdinalPatterns(m = 3)), x)

# Some more sophisticated ways of estimating probabilities:
ps = probabilities(BayesianRegularization(OrdinalPatterns(m = 3)), x)
ps = probabilities(Shrinkage(ValueHistogram(RectangularBinning(5))), x)

# Only the `RelativeAmount` estimator works with non-counting based outcome spaces,
# like for example `WaveletOverlap`.
ps = probabilities(RelativeAmount(WaveletOverlap()), x) # works
ps = probabilities(BayesianRegularization(WaveletOverlap()), x) # errors</code></pre><pre><code class="nohighlight hljs">probabilities(x::Vector_or_SSSet) → p::Probabilities</code></pre><p>Estimate probabilities by using directly counting the elements of <code>x</code>, assuming that <code>Ω = sort(unique(x))</code>, i.e. that the outcome space is the unique elements of <code>x</code>. This is mostly useful when <code>x</code> contains categorical data. It is syntactically equivalent to <code>probabilities(RelativeAmount(CountOccurrences()), x)</code>.</p><p>See also: <a href="#ComplexityMeasures.probabilities_and_outcomes"><code>probabilities_and_outcomes</code></a>, <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>, <a href="#ComplexityMeasures.allprobabilities_and_outcomes"><code>allprobabilities_and_outcomes</code></a>, <a href="#ComplexityMeasures.Probabilities"><code>Probabilities</code></a>, <a href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L110-L177">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.probabilities_and_outcomes" href="#ComplexityMeasures.probabilities_and_outcomes"><code>ComplexityMeasures.probabilities_and_outcomes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">probabilities_and_outcomes(est, x)</code></pre><p>Return <code>probs, outs</code>, where <code>probs = probabilities(est, x)</code> and <code>outs[i]</code> is the outcome with probability <code>probs[i]</code>. The element type of <code>outs</code> depends on the estimator. <code>outs</code> is a subset of the <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a> of <code>est</code>.</p><p>See also <a href="#ComplexityMeasures.outcomes"><code>outcomes</code></a>, <a href="#ComplexityMeasures.total_outcomes"><code>total_outcomes</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L182-L191">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.probabilities!" href="#ComplexityMeasures.probabilities!"><code>ComplexityMeasures.probabilities!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">probabilities!(s, args...)</code></pre><p>Similar to <code>probabilities(args...)</code>, but allows pre-allocation of temporarily used containers <code>s</code>.</p><p>Only works for certain estimators. See for example <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L196-L203">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.allprobabilities" href="#ComplexityMeasures.allprobabilities"><code>ComplexityMeasures.allprobabilities</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">allprobabilities(est::ProbabilitiesEstimator, x::Array_or_SSSet) → p
allprobabilities(o::OutcomeSpace, x::Array_or_SSSet) → p</code></pre><p>The same as <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>, but ensures that outcomes with <code>0</code> probability are explicitly added in the returned vector. This means that <code>p[i]</code> is the probability of <code>ospace[i]</code>, with <code>ospace =</code><a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a><code>(est, x)</code>.</p><p>This function is useful in cases where one wants to compare the probability mass functions of two different input data <code>x, y</code> under the same estimator. E.g., to compute the KL-divergence of the two PMFs assumes that the obey the same indexing. This is not true for <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> even with the same <code>est</code>, due to the skipping of 0 entries, but it is true for <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L217-L230">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.allprobabilities_and_outcomes" href="#ComplexityMeasures.allprobabilities_and_outcomes"><code>ComplexityMeasures.allprobabilities_and_outcomes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">allprobabilities_and_outcomes(o::OutcomeSpace, x::Array_or_SSSet) → (p, Ω)
allprobabilities_and_outcomes(est::ProbabilitiesEstimator, x::Array_or_SSSet) → (p, Ω)</code></pre><p>The same as <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>, but also returns the outcome space <code>Ω</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L244-L249">source</a></section></article><h2 id="Counts"><a class="docs-heading-anchor" href="#Counts">Counts</a><a id="Counts-1"></a><a class="docs-heading-anchor-permalink" href="#Counts" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.counts" href="#ComplexityMeasures.counts"><code>ComplexityMeasures.counts</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">counts(o::OutcomeSpace, x) → cts::Vector{Int}</code></pre><p>Like <a href="#ComplexityMeasures.counts_and_outcomes"><code>counts_and_outcomes</code></a>, but only returns the counts.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/counts.jl#L78-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.counts_and_outcomes" href="#ComplexityMeasures.counts_and_outcomes"><code>ComplexityMeasures.counts_and_outcomes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">counts_and_outcomes(o::OutcomeSpace, x) → (cts::Vector{Int}, Ω::Vector)</code></pre><p>Count how often each outcome <code>Ωᵢ ∈ Ω</code> appears in the (encoded) input data <code>x</code>, where <code>Ω = outcome_space(o, x)</code>.</p><p><strong>Description</strong></p><p>For <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>s that uses <a href="#ComplexityMeasures.encode"><code>encode</code></a> to discretize, it is possible to count how often each outcome <span>$\omega_i \in \Omega$</span>, where <span>$\Omega$</span> is the set of possible outcomes, is observed in the discretized/encoded input data. Thus, we can assign to each outcome <span>$\omega_i$</span> a count <span>$f(\omega_i)$</span>, such that <span>$\sum_{i=1}^N f(\omega_i) = N$</span>, where <span>$N$</span> is the number of observations in the (encoded) input data. <code>counts_and_outcomes</code> returns the counts <span>$f(\omega_i)_{obs}$</span> and outcomes only for the <em>observed</em> outcomes <span>$\omega_i^{obs}$</span> (those outcomes that actually appear in the input data). If you need the counts for <em>unobserved</em> outcomes as well, use <a href="#ComplexityMeasures.allcounts_and_outcomes"><code>allcounts_and_outcomes</code></a>.</p><p>Returns the <code>cts</code> and <code>Ω</code> as a tuple where <code>length(cts) == length(Ω)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/counts.jl#L24-L44">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.allcounts_and_outcomes" href="#ComplexityMeasures.allcounts_and_outcomes"><code>ComplexityMeasures.allcounts_and_outcomes</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">allcounts_and_outcomes(o::OutcomeSpace, x::Array_or_SSSet) → (cts::Vector{Int}, Ω::Vector)</code></pre><p>Like <a href="#ComplexityMeasures.counts_and_outcomes"><code>counts_and_outcomes</code></a>, but ensures that <em>all</em> outcomes <code>Ωᵢ ∈ Ω</code>, where <code>Ω = outcome_space(o, x)</code>), are included.</p><p>Returns the <code>cts</code> and <code>Ω</code> as a tuple where <code>length(cts) == length(Ω)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/counts.jl#L49-L56">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.is_counting_based" href="#ComplexityMeasures.is_counting_based"><code>ComplexityMeasures.is_counting_based</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">is_counting_based(o::OutcomeSpace)</code></pre><p>Return <code>true</code> if the <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> <code>o</code> is counting-based, and <code>false</code> otherwise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/counts.jl#L87-L91">source</a></section></article><h2 id="probability_estimators"><a class="docs-heading-anchor" href="#probability_estimators">Probability estimators</a><a id="probability_estimators-1"></a><a class="docs-heading-anchor-permalink" href="#probability_estimators" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.ProbabilitiesEstimator" href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ComplexityMeasures.ProbabilitiesEstimator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ProbabilitiesEstimator</code></pre><p>The supertype for all probabilities estimators.</p><p>The role of the probabilities estimator is to convert (pseudo-)counts to probabilities. Currently, the implementation of all probabilities estimators assume <em>finite</em> outcome space with known cardinality (i.e. the user must <em>model</em>/<em>assume</em> what this outcome space is). Therefore, <code>ProbabilitiesEstimator</code> accept an <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> as the first argument, which specifies the set of possible outcomes.</p><p><strong>Implementations</strong></p><p>The default probabilities estimator is <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a>, which is compatible with any <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>. The following estimators only support counting-based outcomes.</p><ul><li><a href="#ComplexityMeasures.Shrinkage"><code>Shrinkage</code></a>.</li><li><a href="#ComplexityMeasures.BayesianRegularization"><code>BayesianRegularization</code></a>.</li><li><a href="@ref"><code>AddConstant</code></a>.</li></ul><p><strong>Description</strong></p><p>In ComplexityMeasures.jl, probability mass functions are estimated from data by defining a set of possible outcomes <span>$\Omega = \{\omega_1, \omega_2, \ldots, \omega_L \}$</span> (by specifying an <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>), and assigning to each outcome <span>$\omega_i$</span> a probability <span>$p(\omega_i)$</span>, such that <span>$\sum_{i=1}^N p(\omega_i) = 1$</span> (by specifying a <code>ProbabilitiesEstimator</code>).</p><p><strong>Used with</strong></p><ul><li><a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>/<a href="#ComplexityMeasures.probabilities_and_outcomes"><code>probabilities_and_outcomes</code></a> for estimating a probability   distribution over some <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> from input data.</li><li><a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>/<a href="#ComplexityMeasures.allprobabilities_and_outcomes"><code>allprobabilities_and_outcomes</code></a> for estimating a   probability distribution from input data, guaranteeing inclusion of zero-probability   outcomes.</li></ul><p>The returned probabilities <code>p</code> are a <a href="#ComplexityMeasures.Probabilities"><code>Probabilities</code></a> (<code>Vector</code>-like), where each element <code>p[i]</code> is the probability of the outcome <code>ω[i]</code>. Using an <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> directly as input to <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> or related functions is also possible, and is equivalent to using the <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a> estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/probabilities.jl#L47-L88">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.RelativeAmount" href="#ComplexityMeasures.RelativeAmount"><code>ComplexityMeasures.RelativeAmount</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RelativeAmount &lt;: ProbabilitiesEstimator
RelativeAmount(o::OutcomeSpace)</code></pre><p>The <code>RelativeAmount</code> estimator is used with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> and related functions to estimate probabilities over the given <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> using maximum likelihood estimation (MLE), also called plug-in estimation. See <a href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a> for usage.</p><p><strong>Description</strong></p><p>Consider a length-<code>m</code> outcome space <span>$\Omega$</span> and random sample of length <code>N</code>. The maximum likelihood estimate of the probability of the <code>k</code>-th outcome <span>$\omega_k$</span> is</p><p class="math-container">\[p(\omega_k) = \dfrac{n_k}{N},\]</p><p>where <span>$n_k$</span> is the number of times the <code>k</code>-th outcome was observed in the (encoded) sample.</p><p>This estimation is known as <em>Maximum Likelihood Estimation</em>. However, <code>RelativeAmount</code> also serves as the fall-back probabilities estimator for <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>s that are not count-based and only yield &quot;pseudo-counts&quot;, for example <a href="#ComplexityMeasures.WaveletOverlap"><code>WaveletOverlap</code></a> or <a href="#ComplexityMeasures.PowerSpectrum"><code>PowerSpectrum</code></a>. These outcome spaces do not yield counts, but pre-normalized numbers that can be treated as &quot;relative frequencies&quot; or &quot;relative power&quot;. Hence, this estimator is called <code>RelativeAmount</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using ComplexityMeasures
x = cumsum(randn(100))
ps = probabilities(OrdinalPatterns(m = 3), x) # RelativeAmount is the default estimator
ps_mle = probabilities(RelativeAmount(OrdinalPatterns(m = 3)), x) # equivalent
ps == ps_mle # true</code></pre><p>See also: <a href="#ComplexityMeasures.BayesianRegularization"><code>BayesianRegularization</code></a>, <a href="#ComplexityMeasures.Shrinkage"><code>Shrinkage</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/probabilities_estimators/RelativeAmount.jl#L3-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.BayesianRegularization" href="#ComplexityMeasures.BayesianRegularization"><code>ComplexityMeasures.BayesianRegularization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BayesianRegularization &lt;: ProbabilitiesEstimator
BayesianRegularization(outcome_space::OutcomeSpace, a = 1.0)</code></pre><p>The <code>BayesianRegularization</code> estimator is used with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> and related functions to estimate probabilities over the given <code>m</code>-element counting-based <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> using Bayesian regularization of cell counts (Hausser &amp; Strimmer, 2009)<sup class="footnote-reference"><a id="citeref-Hausser2009" href="#footnote-Hausser2009">[Hausser2009]</a></sup>. See <a href="#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a> for usage.</p><p><strong>Outcome space requirements</strong></p><p>This estimator only works with counting-compatible outcome spaces.</p><p><strong>Description</strong></p><p>The <code>BayesianRegularization</code> estimator estimates the probability of the <span>$k$</span>-th outcome <span>$\omega_{k}$</span> is</p><p class="math-container">\[\omega_{k}^{\text{BayesianRegularization}} = \dfrac{n_k + a_k}{n + A},\]</p><p>where <span>$n$</span> is the number of samples in the input data, <span>$n_k$</span> is the observed counts for the outcome <span>$\omega_{k}$</span>, and <span>$A = \sum_{i=1}^k a_k$</span>.</p><p><strong>Picking <code>a</code></strong></p><p>There are many common choices of priors, some of which are listed in Hausser &amp; Strimmer (2009)<sup class="footnote-reference"><a id="citeref-Hausser2009" href="#footnote-Hausser2009">[Hausser2009]</a></sup>. They include</p><ul><li><code>a == 0</code>, which is equivalent to the <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a> estimator.</li><li><code>a == 0.5</code> (Jeffrey&#39;s prior)</li><li><code>a == 1</code> (BayesianRegularization-Laplace uniform prior)</li></ul><p><code>a</code> can also be chosen as a vector of real numbers. Then, if used with <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>, it is required that <code>length(a) == total_outcomes(o, x)</code>, where <code>x</code> is the input data and <code>o</code> is the <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>. If used with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>, then <code>length(a)</code> must match the number of <em>observed</em> outcomes (you can check this using <a href="#ComplexityMeasures.probabilities_and_outcomes"><code>probabilities_and_outcomes</code></a>). The choice of <code>a</code> can severely impact the estimation errors of the probabilities, and the errors depend both on the choice of <code>a</code> and on the sampling scenario<sup class="footnote-reference"><a id="citeref-Hausser2009" href="#footnote-Hausser2009">[Hausser2009]</a></sup>.</p><p><strong>Assumptions</strong></p><p>The <code>BayesianRegularization</code> estimator assumes a fixed and known <code>m</code>. Thus, using it with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> and <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a> will yield different results, depending on whether all outcomes are observed in the input data or not. For <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>, <code>m</code> is the number of <em>observed</em> outcomes. For <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>, <code>m = total_outcomes(o, x)</code>, where <code>o</code> is the <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> and <code>x</code> is the input data.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If used with <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>/<a href="#ComplexityMeasures.allprobabilities_and_outcomes"><code>allprobabilities_and_outcomes</code></a>, then outcomes which have not been observed may be assigned non-zero probabilities. This might affect your results if using e.g. <a href="#ComplexityMeasures.missing_outcomes"><code>missing_outcomes</code></a>.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using ComplexityMeasures
x = cumsum(randn(100))
ps_bayes = probabilities(BayesianRegularization(OrdinalPatterns(m = 3), a = 0.5), x)</code></pre><p>See also: <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a>, <a href="#ComplexityMeasures.Shrinkage"><code>Shrinkage</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/probabilities_estimators/BayesianRegularization.jl#L3-L73">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.Shrinkage" href="#ComplexityMeasures.Shrinkage"><code>ComplexityMeasures.Shrinkage</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Shrinkage{&lt;:OutcomeSpace} &lt;: ProbabilitiesEstimator
Shrinkage(model::OutcomeSpace; t = nothing, λ = nothing)</code></pre><p>The <code>Shrinkage</code> estimator is used with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> and related functions to estimate probabilities over the given <code>m</code>-element counting-based <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> using James-Stein-type shrinkage (James &amp; Stein, 1961)<sup class="footnote-reference"><a id="citeref-JamesStein1961" href="#footnote-JamesStein1961">[JamesStein1961]</a></sup>, as presented in Hausser &amp; Strimmer (2009)<sup class="footnote-reference"><a id="citeref-Hausser2009" href="#footnote-Hausser2009">[Hausser2009]</a></sup>.</p><p><strong>Description</strong></p><p>The <code>Shrinkage</code> estimator estimates a cell probability <span>$\theta_{k}^{\text{Shrink}}$</span> as</p><p class="math-container">\[\theta_{k}^{\text{Shrink}} = \lambda t_k + (1-\lambda) \hat{\theta}_k^{RelativeAmount},\]</p><p>where <span>$\lambda \in [0, 1]$</span> is the shrinkage intensity (<span>$\lambda = 0$</span> means no shrinkage, and <span>$\lambda = 1$</span> means full shrinkage), and <span>$t_k$</span> is the shrinkage target. Hausser &amp; Strimmer (2009)<sup class="footnote-reference"><a id="citeref-Hausser2009" href="#footnote-Hausser2009">[Hausser2009]</a></sup> picks <span>$t_k = 1/m$</span>, i.e. the uniform distribution.</p><p>If <code>t == nothing</code>, then <span>$t_k$</span> is set to <span>$1/m$</span> for all <span>$k$</span>, as in Hausser &amp; Strimmer (2009)<sup class="footnote-reference"><a id="citeref-Hausser2009" href="#footnote-Hausser2009">[Hausser2009]</a></sup>. If <code>λ == nothing</code> (the default), then the shrinkage intensity is optimized according to Hausser &amp; Strimmer (2009)<sup class="footnote-reference"><a id="citeref-Hausser2009" href="#footnote-Hausser2009">[Hausser2009]</a></sup>. Hence, you should probably not pick <code>λ</code> nor <code>t</code> manually, unless you know what you are doing.</p><p><strong>Assumptions</strong></p><p>The <code>Shrinkage</code> estimator assumes a fixed and known number of outcomes <code>m</code>. Thus, using it with <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a> and <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a> will yield different results, depending on whether all outcomes are observed in the input data or not. For <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>, <code>m</code> is the number of <em>observed</em> outcomes. For <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>, <code>m = total_outcomes(o, x)</code>, where <code>o</code> is the <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> and <code>x</code> is the input data.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If used with <a href="#ComplexityMeasures.allprobabilities"><code>allprobabilities</code></a>/<a href="#ComplexityMeasures.allprobabilities_and_outcomes"><code>allprobabilities_and_outcomes</code></a>, then outcomes which have not been observed may be assigned non-zero probabilities. This might affect your results if using e.g. <a href="#ComplexityMeasures.missing_outcomes"><code>missing_outcomes</code></a>.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using ComplexityMeasures
x = cumsum(randn(100))
ps_shrink = probabilities(Shrinkage(OrdinalPatterns(m = 3)), x)</code></pre><p>See also: <a href="#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a>, <a href="#ComplexityMeasures.BayesianRegularization"><code>BayesianRegularization</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/probabilities_estimators/Shrinkage.jl#L4-L64">source</a></section></article><h2 id="encodings"><a class="docs-heading-anchor" href="#encodings">Encodings API</a><a id="encodings-1"></a><a class="docs-heading-anchor-permalink" href="#encodings" title="Permalink"></a></h2><p>Count-based <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>s first &quot;encode&quot; input data into an intermediate representation indexed by the positive integers. This intermediate representation is called an &quot;encoding&quot;.</p><p>The encodings API is defined by:</p><ul><li><a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a></li><li><a href="#ComplexityMeasures.encode"><code>encode</code></a></li><li><a href="#ComplexityMeasures.decode"><code>decode</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.Encoding" href="#ComplexityMeasures.Encoding"><code>ComplexityMeasures.Encoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Encoding</code></pre><p>The supertype for all encoding schemes. Encodings always encode elements of input data into the positive integers. The encoding API is defined by the functions <a href="#ComplexityMeasures.encode"><code>encode</code></a> and <a href="#ComplexityMeasures.decode"><code>decode</code></a>. Some probability estimators utilize encodings internally.</p><p>Current available encodings are:</p><ul><li><a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a>.</li><li><a href="#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a>.</li><li><a href="#ComplexityMeasures.RectangularBinEncoding"><code>RectangularBinEncoding</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/encodings.jl#L3-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.encode" href="#ComplexityMeasures.encode"><code>ComplexityMeasures.encode</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">encode(c::Encoding, χ) -&gt; i::Int</code></pre><p>Encode an element <code>χ ∈ x</code> of input data <code>x</code> (those given to <a href="#ComplexityMeasures.probabilities"><code>probabilities</code></a>) using encoding <code>c</code>.</p><p>The special value of <code>-1</code> is reserved as a return value for inappropriate elements <code>χ</code> that cannot be encoded according to <code>c</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/encodings.jl#L19-L27">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.decode" href="#ComplexityMeasures.decode"><code>ComplexityMeasures.decode</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">decode(c::Encoding, i::Int) -&gt; ω</code></pre><p>Decode an encoded element <code>i</code> into the outcome <code>ω ∈ Ω</code> it corresponds to.</p><p><code>Ω</code> is the <a href="#ComplexityMeasures.outcome_space"><code>outcome_space</code></a> of a probabilities estimator that uses encoding <code>c</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/core/encodings.jl#L30-L36">source</a></section></article><h3 id="Available-encodings"><a class="docs-heading-anchor" href="#Available-encodings">Available encodings</a><a id="Available-encodings-1"></a><a class="docs-heading-anchor-permalink" href="#Available-encodings" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.OrdinalPatternEncoding" href="#ComplexityMeasures.OrdinalPatternEncoding"><code>ComplexityMeasures.OrdinalPatternEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OrdinalPatternEncoding &lt;: Encoding
OrdinalPatternEncoding(m::Int, lt = ComplexityMeasures.isless_rand)</code></pre><p>An encoding scheme that <a href="#ComplexityMeasures.encode"><code>encode</code></a>s length-<code>m</code> vectors into their permutation/ordinal patterns and then into the integers based on the Lehmer code. It is used by <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> and similar estimators, see that for a description of the outcome space.</p><p>The ordinal/permutation pattern of a vector <code>χ</code> is simply <code>sortperm(χ)</code>, which gives the indices that would sort <code>χ</code> in ascending order.</p><p><strong>Description</strong></p><p>The Lehmer code, as implemented here, is a bijection between the set of <code>factorial(m)</code> possible permutations for a length-<code>m</code> sequence, and the integers <code>1, 2, …, factorial(m)</code>. The encoding step uses algorithm 1 in Berger et al. (2019)<sup class="footnote-reference"><a id="citeref-Berger2019" href="#footnote-Berger2019">[Berger2019]</a></sup>, which is highly optimized. The decoding step is much slower due to missing optimizations (pull requests welcomed!).</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ComplexityMeasures

julia&gt; χ = [4.0, 1.0, 9.0];

julia&gt; c = OrdinalPatternEncoding(3);

julia&gt; i = encode(c, χ)
3

julia&gt; decode(c, i)
3-element SVector{3, Int64} with indices SOneTo(3):
 2
 1
 3</code></pre><p>If you want to encode something that is already a permutation pattern, then you can use the non-exported <code>permutation_to_integer</code> function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/encoding_implementations/ordinal_pattern.jl#L6-L51">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.GaussianCDFEncoding" href="#ComplexityMeasures.GaussianCDFEncoding"><code>ComplexityMeasures.GaussianCDFEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GaussianCDFEncoding &lt;: Encoding
GaussianCDFEncoding(; μ, σ, c::Int = 3)</code></pre><p>An encoding scheme that <a href="#ComplexityMeasures.encode"><code>encode</code></a>s a scalar value into one of the integers <code>sᵢ ∈ [1, 2, …, c]</code> based on the normal cumulative distribution function (NCDF), and <a href="#ComplexityMeasures.decode"><code>decode</code></a>s the <code>sᵢ</code> into subintervals of <code>[0, 1]</code> (with some loss of information).</p><p>Notice that the decoding step does not yield an element of any outcome space of the estimators that use <code>GaussianCDFEncoding</code> internally, such as <a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a>. That is because these estimators additionally delay embed the encoded data.</p><p><strong>Description</strong></p><p><code>GaussianCDFEncoding</code> first maps an input point <span>$x$</span>  (scalar) to a new real number <span>$y_ \in [0, 1]$</span> by using the normal cumulative distribution function (CDF) with the given mean <code>μ</code> and standard deviation <code>σ</code>, according to the map</p><p class="math-container">\[x \to y : y = \dfrac{1}{ \sigma
    \sqrt{2 \pi}} \int_{-\infty}^{x} e^{(-(x - \mu)^2)/(2 \sigma^2)} dx.\]</p><p>Next, the interval <code>[0, 1]</code> is equidistantly binned and enumerated <span>$1, 2, \ldots, c$</span>,  and <span>$y$</span> is linearly mapped to one of these integers using the linear map  <span>$y \to z : z = \text{floor}(y(c-1)) + 1$</span>.</p><p>Because of the floor operation, some information is lost, so when used with <a href="#ComplexityMeasures.decode"><code>decode</code></a>, each decoded <code>sᵢ</code> is mapped to a <em>subinterval</em> of <code>[0, 1]</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ComplexityMeasures, Statistics

julia&gt; x = [0.1, 0.4, 0.7, -2.1, 8.0];

julia&gt; μ, σ = mean(x), std(x); encoding = GaussianCDFEncoding(; μ, σ, c = 5)

julia&gt; es = encode.(Ref(encoding), x)
5-element Vector{Int64}:
 2
 2
 3
 1
 5

julia&gt; decode(encoding, 3)
2-element SVector{2, Float64} with indices SOneTo(2):
 0.4
 0.6</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/encoding_implementations/gaussian_cdf.jl#L5-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ComplexityMeasures.RectangularBinEncoding" href="#ComplexityMeasures.RectangularBinEncoding"><code>ComplexityMeasures.RectangularBinEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RectangularBinEncoding &lt;: Encoding
RectangularBinEncoding(binning::RectangularBinning, x)
RectangularBinEncoding(binning::FixedRectangularBinning)</code></pre><p>An encoding scheme that <a href="#ComplexityMeasures.encode"><code>encode</code></a>s points <code>χ ∈ x</code> into their histogram bins.</p><p>The first call signature simply initializes a <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> and then calls the second call signature.</p><p>See <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> for info on mapping points to bins.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/fc6823402e8ad4127e33c8eb0a95af639e17933d/src/encoding_implementations/rectangular_binning.jl#L101-L112">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-BandtPompe2002"><a class="tag is-link" href="#citeref-BandtPompe2002">BandtPompe2002</a>Bandt, Christoph, and Bernd Pompe. &quot;Permutation entropy: a natural complexity measure for timeseries.&quot; Physical review letters 88.17 (2002): 174102.</li><li class="footnote" id="footnote-Zunino2017"><a class="tag is-link" href="#citeref-Zunino2017">Zunino2017</a>Zunino, L., Olivares, F., Scholkmann, F., &amp; Rosso, O. A. (2017). Permutation entropy based timeseries analysis: Equalities in the input signal can lead to false conclusions. Physics Letters A, 381(22), 1883-1892.</li><li class="footnote" id="footnote-He2016"><a class="tag is-link" href="#citeref-He2016">He2016</a>He, S., Sun, K., &amp; Wang, H. (2016). Multivariate permutation entropy and its application for complexity analysis of chaotic systems. Physica A: Statistical Mechanics and its Applications, 461, 812-823.</li><li class="footnote" id="footnote-Fadlallah2013"><a class="tag is-link" href="#citeref-Fadlallah2013">Fadlallah2013</a>Fadlallah, et al. &quot;Weighted-permutation entropy: A complexity measure for time series incorporating amplitude information.&quot; Physical Review E 87.2 (2013): 022911.</li><li class="footnote" id="footnote-Azami2016"><a class="tag is-link" href="#citeref-Azami2016">Azami2016</a>Azami, H., &amp; Escudero, J. (2016). Amplitude-aware permutation entropy: Illustration in spike detection and signal segmentation. Computer methods and programs in biomedicine, 128, 40-51.</li><li class="footnote" id="footnote-Rostaghi2016"><a class="tag is-link" href="#citeref-Rostaghi2016">Rostaghi2016</a>Rostaghi, M., &amp; Azami, H. (2016). Dispersion entropy: A measure for time-series analysis. IEEE Signal Processing Letters, 23(5), 610-614.</li><li class="footnote" id="footnote-Li2018"><a class="tag is-link" href="#citeref-Li2018">Li2018</a>Li, G., Guan, Q., &amp; Yang, H. (2018). Noise reduction method of underwater acoustic signals based on CEEMDAN, effort-to-compress complexity, refined composite multiscale dispersion entropy and wavelet threshold denoising. InformationMeasure, 21(1), 11.</li><li class="footnote" id="footnote-Diego2019"><a class="tag is-link" href="#citeref-Diego2019">Diego2019</a>Diego, D., Haaga, K. A., &amp; Hannisdal, B. (2019). Transfer entropy computation using the Perron-Frobenius operator. Physical Review E, 99(4), 042212.</li><li class="footnote" id="footnote-PrichardTheiler1995"><a class="tag is-link" href="#citeref-PrichardTheiler1995">PrichardTheiler1995</a>Prichard, D., &amp; Theiler, J. (1995). Generalized redundancies for time series analysis. Physica D: Nonlinear Phenomena, 84(3-4), 476-493.</li><li class="footnote" id="footnote-Rosso2001"><a class="tag is-link" href="#citeref-Rosso2001">Rosso2001</a>Rosso et al. (2001). Wavelet entropy: a new tool for analysis of short duration brain electrical signals. Journal of neuroscience methods, 105(1), 65-75.</li><li class="footnote" id="footnote-Llanos2016"><a class="tag is-link" href="#citeref-Llanos2016">Llanos2016</a>Llanos et al., <em>Power spectral entropy as an information-theoretic correlate of manner of articulation in American English</em>, <a href="https://doi.org/10.1121/1.4976109">The Journal of the Acoustical Society of America 141, EL127 (2017)</a></li><li class="footnote" id="footnote-Tian2017"><a class="tag is-link" href="#citeref-Tian2017">Tian2017</a>Tian et al, <em>Spectral InformationMeasure Can Predict Changes of Working Memory Performance Reduced by Short-Time Training in the Delayed-Match-to-Sample Task</em>, <a href="https://doi.org/10.3389/fnhum.2017.00437">Front. Hum. Neurosci.</a></li><li class="footnote" id="footnote-Wang2020"><a class="tag is-link" href="#citeref-Wang2020">Wang2020</a>Wang, X., Si, S., &amp; Li, Y. (2020). Multiscale diversity entropy: A novel dynamical measure for fault diagnosis of rotating machinery. IEEE Transactions on Industrial Informatics, 17(8), 5419-5429.</li><li class="footnote" id="footnote-Ribeiro2012"><a class="tag is-link" href="#citeref-Ribeiro2012">Ribeiro2012</a>Ribeiro et al. (2012). Complexity-entropy causality plane as a complexity measure for two-dimensional patterns. https://doi.org/10.1371/journal.pone.0040689</li><li class="footnote" id="footnote-Schlemmer2018"><a class="tag is-link" href="#citeref-Schlemmer2018">Schlemmer2018</a>Schlemmer et al. (2018). Spatiotemporal Permutation InformationMeasure as a Measure for Complexity of Cardiac Arrhythmia. https://doi.org/10.3389/fphy.2018.00039</li><li class="footnote" id="footnote-Azami2019"><a class="tag is-link" href="#citeref-Azami2019">Azami2019</a>Azami, H., da Silva, L. E. V., Omoto, A. C. M., &amp; Humeau-Heurtier, A. (2019). Two-dimensional dispersion entropy: An information-theoretic method for irregularity analysis of images. Signal Processing: Image Communication, 75, 178-187.</li><li class="footnote" id="footnote-Hausser2009"><a class="tag is-link" href="#citeref-Hausser2009">Hausser2009</a>Hausser, J., &amp; Strimmer, K. (2009). Entropy inference and the James-Stein estimator, with application to nonlinear gene association networks. Journal of Machine Learning Research, 10(7).</li><li class="footnote" id="footnote-JamesStein1961"><a class="tag is-link" href="#citeref-JamesStein1961">JamesStein1961</a>James, W., &amp; Stein, C. (1992). Estimation with quadratic loss. In Breakthroughs in statistics: Foundations and basic theory (pp. 443-460). New York, NY: Springer New York.</li><li class="footnote" id="footnote-Hausser2009"><a class="tag is-link" href="#citeref-Hausser2009">Hausser2009</a>Hausser, J., &amp; Strimmer, K. (2009). Entropy inference and the James-Stein estimator, with application to nonlinear gene association networks. Journal of Machine Learning Research, 10(7).</li><li class="footnote" id="footnote-Berger2019"><a class="tag is-link" href="#citeref-Berger2019">Berger2019</a>Berger et al. &quot;Teaching Ordinal Patterns to a Computer: Efficient Encoding Algorithms Based on the Lehmer Code.&quot; Entropy 21.10 (2019): 1023.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Tutorial</a><a class="docs-footer-nextpage" href="../information_measures/">Information measures (entropies and co.) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Sunday 20 August 2023 18:54">Sunday 20 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
