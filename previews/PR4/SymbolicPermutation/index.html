<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Permutation (symbolic) · Entropies.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Entropies.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Documentation</a></li><li><span class="tocitem">Estimation</span><ul><li class="is-active"><a class="tocitem" href>Permutation (symbolic)</a><ul class="internal"><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li><a class="tocitem" href="#Utils"><span>Utils</span></a></li></ul></li><li><a class="tocitem" href="../VisitationFrequency/">Visitation frequency</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Estimation</a></li><li class="is-active"><a href>Permutation (symbolic)</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Permutation (symbolic)</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kahaaga/Entropies.jl/blob/master/docs/src/SymbolicPermutation.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Permutation-(symbolic)"><a class="docs-heading-anchor" href="#Permutation-(symbolic)">Permutation (symbolic)</a><a id="Permutation-(symbolic)-1"></a><a class="docs-heading-anchor-permalink" href="#Permutation-(symbolic)" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="Entropies.SymbolicPermutation" href="#Entropies.SymbolicPermutation"><code>Entropies.SymbolicPermutation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SymbolicPermutation(m::Int; b::Real = 2)</code></pre><p>A symbolic permutation probabilities estimator using motifs of length <code>m</code>, based on Bandt &amp; Pompe (2002)<sup class="footnote-reference"><a id="citeref-BandtPompe2002" href="#footnote-BandtPompe2002">[BandtPompe2002]</a></sup>.</p><p>If the estimator is used for entropy computation, then the entropy is computed  to base <code>b</code> (the default <code>b = 2</code> gives the entropy in bits).</p><p>The motif length must be ≥ 2. By default <code>m = 2</code>, which is the shortest  possible permutation length which retains any meaningful dynamical information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/Entropies.jl/blob/b86c73449e931a6f347a7c958bfeb778a03bee4d/src/symbolic/symbolic_permutation.jl#L11-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Entropies.entropy-Union{Tuple{T}, Tuple{N}, Tuple{Dataset{N,T},SymbolicPermutation}, Tuple{Dataset{N,T},SymbolicPermutation,Real}} where T where N" href="#Entropies.entropy-Union{Tuple{T}, Tuple{N}, Tuple{Dataset{N,T},SymbolicPermutation}, Tuple{Dataset{N,T},SymbolicPermutation,Real}} where T where N"><code>Entropies.entropy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">entropy(x::Dataset, est::SymbolicPermutation, α::Real = 1)
entropy!(s::Vector{Int}, x::Dataset, est::SymbolicPermutation, α::Real = 1)</code></pre><p>Compute the generalized order <code>α</code> permutation entropy of <code>x</code>, using symbol size <code>est.m</code>.</p><p><strong>Probability estimation</strong></p><p>An unordered symbol frequency histogram is obtained by symbolizing the points in <code>x</code>, using <a href="@ref"><code>probabilities(::Dataset{N, T}, ::SymbolicPermutation)</code></a>. Sum-normalizing this histogram yields a probability distribution over the symbols </p><p>A pre-allocated symbol array <code>s</code>, where <code>length(x) = length(s)</code>, can be provided to  save some memory allocations if the permutation entropy is to be computed for multiple data sets.</p><p><strong>Entropy estimation</strong></p><p>After the symbolization histogram/distribution has been obtained, the order <code>α</code> generalized entropy  is computed from that sum-normalized symbol distribution.</p><p><em>Note: Do not confuse the order of the generalized entropy (<code>α</code>) with the order <code>m</code> of the  permutation entropy (<code>est.m</code>, which controls the symbol size). Permutation entropy is usually  estimated with <code>α = 1</code>, but the implementation here allows the generalized entropy of any  dimension to be computed from the symbol frequency distribution.</em></p><p>Let <span>$p$</span> be an array of probabilities (summing to 1). Then the Rényi entropy is</p><div>\[H_\alpha(p) = \frac{1}{1-\alpha} \log \left(\sum_i p[i]^\alpha\right)\]</div><p>and generalizes other known entropies, like e.g. the information entropy (<span>$\alpha = 1$</span>, see <sup class="footnote-reference"><a id="citeref-Shannon1948" href="#footnote-Shannon1948">[Shannon1948]</a></sup>), the maximum entropy (<span>$\alpha=0$</span>, also known as Hartley entropy), or the correlation entropy (<span>$\alpha = 2$</span>, also known as collision entropy).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/Entropies.jl/blob/b86c73449e931a6f347a7c958bfeb778a03bee4d/src/symbolic/symbolic_permutation.jl#L125-L166">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Entropies.probabilities-Union{Tuple{T}, Tuple{N}, Tuple{Dataset{N,T},SymbolicPermutation}} where T where N" href="#Entropies.probabilities-Union{Tuple{T}, Tuple{N}, Tuple{Dataset{N,T},SymbolicPermutation}} where T where N"><code>Entropies.probabilities</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">probabilities(x::Dataset, est::SymbolicPermutation)
probabilities!(s::Vector{Int}, x::Dataset, est::SymbolicPermutation)</code></pre><p>Compute the unordered probabilities of the occurrence of symbol sequences constructed from the data <code>x</code>.  A pre-allocated symbol array <code>s</code>, where <code>length(x) = length(s)</code>, can be provided to  save some memory allocations if the probabilities are to be computed for multiple data sets.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/Entropies.jl/blob/b86c73449e931a6f347a7c958bfeb778a03bee4d/src/symbolic/symbolic_permutation.jl#L97-L104">source</a></section></article><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><p>This example reproduces the permutation entropy example on the logistic map from Bandt and Pompe (2002).</p><pre><code class="language-julia">using DynamicalSystems, PyPlot, Entropies

ds = Systems.logistic()
rs = 3.5:0.001:4
N_lyap, N_ent = 100000, 10000

# Generate one time series for each value of the logistic parameter r
lyaps, hs_entropies, hs_chaostools = Float64[], Float64[], Float64[]

for r in rs
    ds.p[1] = r
    push!(lyaps, lyapunov(ds, N_lyap))

    # For 1D systems `trajectory` returns a vector, so embed it using τs
    # to get the correct 6d dimension on the embedding
    x = trajectory(ds, N_ent)
    τs = ([-i for i in 0:6-1]...,) # embedding lags
    emb = genembed(x, τs)

    # Pre-allocate symbol vector, one symbol for each point in the embedding - this is faster!
    s = zeros(Int, length(emb));
    push!(hs_entropies, entropy!(s, emb, SymbolicPermutation(6, b = Base.MathConstants.e)))

    # Old ChaosTools.jl style estimation
    push!(hs_chaostools, permentropy(x, 6))
end

f = figure(figsize = (10,6))
a1 = subplot(311)
plot(rs, lyaps); ylim(-2, log(2)); ylabel(&quot;\$\\lambda\$&quot;)
a1.axes.get_xaxis().set_ticklabels([])
xlim(rs[1], rs[end]);

a2 = subplot(312)
plot(rs, hs_chaostools; color = &quot;C1&quot;); xlim(rs[1], rs[end]);
xlabel(&quot;\$r\$&quot;); ylabel(&quot;\$h_6 (ChaosTools.jl)\$&quot;)

a3 = subplot(313)
plot(rs, hs_entropies; color = &quot;C2&quot;); xlim(rs[1], rs[end]);
xlabel(&quot;\$r\$&quot;); ylabel(&quot;\$h_6 (Entropies.jl)\$&quot;)
tight_layout()
savefig(&quot;permentropy.png&quot;)</code></pre><p><img src="../permentropy.png" alt/></p><h2 id="Utils"><a class="docs-heading-anchor" href="#Utils">Utils</a><a id="Utils-1"></a><a class="docs-heading-anchor-permalink" href="#Utils" title="Permalink"></a></h2><p>Some convenience functions for symbolization are provided.</p><article class="docstring"><header><a class="docstring-binding" id="Entropies.symbolize" href="#Entropies.symbolize"><code>Entropies.symbolize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">symbolize(x::Dataset{N, T}, est::SymbolicPermutation) where {N, T} → Vector{Int}</code></pre><p>Symbolize the vectors in <code>x</code> using Algorithm 1 from Berger et al. (2019)<sup class="footnote-reference"><a id="citeref-Berger2019" href="#footnote-Berger2019">[Berger2019]</a></sup>.</p><p>The symbol length is automatically determined from the dimension of the input data.</p><p><strong>Example</strong></p><p>Computing the order 5 permutation entropy for a 7-dimensional dataset.</p><pre><code class="language-julia">using DelayEmbeddings, Entropies
D = Dataset([rand(7) for i = 1:1000])
symbolize(D, SymbolicPermutation(5))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/Entropies.jl/blob/b86c73449e931a6f347a7c958bfeb778a03bee4d/src/symbolic/symbolic_permutation.jl#L35-L54">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Entropies.encode_motif" href="#Entropies.encode_motif"><code>Entropies.encode_motif</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">encode_motif(x, m::Int = length(x))</code></pre><p>Encode the length-<code>m</code> motif <code>x</code> (a vector of indices that would sort some vector <code>v</code> in ascending order)  into its unique integer symbol, using Algorithm 1 in Berger et al. (2019)<sup class="footnote-reference"><a id="citeref-Berger2019" href="#footnote-Berger2019">[Berger2019]</a></sup>.</p><p>Note: no error checking is done to see if <code>length(x) == m</code>, so be sure to provide the correct motif length!</p><p><strong>Example</strong></p><pre><code class="language-julia"># Some random vector
v = rand(5)

# The indices that would sort `v` in ascending order. This is now a permutation 
# of the index permutation (1, 2, ..., 5)
x = sortperm(v)

# Encode this permutation as an integer.
encode_motif(x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/Entropies.jl/blob/b86c73449e931a6f347a7c958bfeb778a03bee4d/src/symbolic/utils.jl#L3-L26">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-BandtPompe2002"><a class="tag is-link" href="#citeref-BandtPompe2002">BandtPompe2002</a>Bandt, Christoph, and Bernd Pompe. &quot;Permutation entropy: a natural complexity measure for time series.&quot; Physical review letters 88.17 (2002): 174102.</li><li class="footnote" id="footnote-Rényi1960"><a class="tag is-link" href="#citeref-Rényi1960">Rényi1960</a>A. Rényi, <em>Proceedings of the fourth Berkeley Symposium on Mathematics, Statistics and Probability</em>, pp 547 (1960)</li><li class="footnote" id="footnote-Shannon1948"><a class="tag is-link" href="#citeref-Shannon1948">Shannon1948</a>C. E. Shannon, Bell Systems Technical Journal <strong>27</strong>, pp 379 (1948)</li><li class="footnote" id="footnote-Berger2019"><a class="tag is-link" href="#citeref-Berger2019">Berger2019</a>Berger, Sebastian, et al. &quot;Teaching Ordinal Patterns to a Computer: Efficient Encoding Algorithms Based on the Lehmer Code.&quot; Entropy 21.10 (2019): 1023.</li><li class="footnote" id="footnote-Berger2019"><a class="tag is-link" href="#citeref-Berger2019">Berger2019</a>Berger, Sebastian, et al. &quot;Teaching Ordinal Patterns to a Computer: Efficient Encoding Algorithms Based on the Lehmer Code.&quot; Entropy 21.10 (2019): 1023.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Documentation</a><a class="docs-footer-nextpage" href="../VisitationFrequency/">Visitation frequency »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 26 October 2020 00:15">Monday 26 October 2020</span>. Using Julia version 1.5.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
