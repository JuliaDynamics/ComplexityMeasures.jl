export walkthrough_entropy
export WalkthroughEntropy

# write into the pre-allocated ùêß‚Çô (a vector containing counts for each unique
# state  up to index n).
function count_occurrences_up_to_n!(ùêß‚Çô, n, x, unique_symbols)
    n <= length(x) || throw(ArgumentError("n cannot be larger than length(x)"))

    for i in eachindex(unique_symbols)
        s = unique_symbols[i]
        for j in 1:n
            if (x[j] == s)
                ùêß‚Çô[i] += 1
            end
        end
    end
    return ùêß‚Çô
end

function visitations_per_position(x, unique_symbols)
    N = length(x)

    ùêß = [zeros(BigInt, length(unique_symbols)) for i = 1:N]
    for n in 1:N
        count_occurrences_up_to_n!(ùêß[n], n, x, unique_symbols)
    end

    return ùêß
end

function entropygenerator(x, method::WalkthroughEntropy, rng = Random.default_rng())
    # ùêî: unique elements in `x`
    # ùêç: the corresponding frequencies (ùêç[i] = # times ùêî[i] occurs).
    ùêî, ùêç = vec_countmap(x)

    # ùêß is a Vector{Vector{Int}}. ùêß[i][j] contains the number of times the unique element
    # ùêî[j] appears in the subsequence `x[1:i]`.
    ùêß = visitations_per_position(x, ùêî)

    init = (
        ùêî = ùêî,
        ùêç = ùêç,
        ùêß = ùêß,
    )

    return EntropyGenerator(method, x, init, rng)
end

function conditional_walkprob(n::Int, N::Int, ùêç, ùêß)
    if (n == 0)
        return 1.0
    else
        ùêß‚Çô = ùêß[n]
        s = length(ùêç)
        a = prod([binomial(ùêç[j], ùêß‚Çô[j]) for j = 1:s])
        b = binomial(BigInt(N), BigInt(n))
        return a / b
    end
end

# TODO: normalization does nothing at the moment, but is only needed for excess entropy,
# so this doesn't affect the walkthrough entropy. See comment inside function.
function _walkthrough_entropy(n::Int, N::Int, ùêç, ùêß; length_normalize = false,
        base = MathConstants.e)

    if (!length_normalize)
        # P(ùêß|ùêç)
        p = conditional_walkprob(n, N, ùêç, ùêß)
        return -log(base, p)
    else
        # P(ùêß|ùêç)
        p = conditional_walkprob(n, N, ùêç, ùêß)

        # NB: Not sure about the normalization step.
        # Why?
        # Citing from paper: P(ùêß|ùêç) is the multivariate hypergeometric probability
        #  distribution (i.e., for sampling without replacement). It has expectation
        # ùîº(ùêß) = nùê©.
        #
        # Length-normalized excess entropy is defined as
        # H(n) = P(ùêß|ùêç) / P(ùîº(ùêß)|ùêç).
        #
        # To compute P(ùîº(ùêß)|ùêç), the elements of ùêß must be integers (because the binomial
        # formula is used). However, ùîº(ùêß) is in general not an integer vector, because ùê© is
        # a probability vector, so the integer-vector product nùê© yields a vector of floats.
        #
        #ùêÑùêß = [ceil(Int, StatsBase.mean(n·µ¢)) for n·µ¢ in ùêß]
        #pùêÑ = conditional_walkprob(n, N, ùêç, ùêß)
        -log(base, p)
    end
end

function (eg::EntropyGenerator{<:WalkthroughEntropy})(n::Int;
        length_normalize = false, base = MathConstants.e)

    ùêî, ùêç, ùêß = getfield.(
        Ref(eg.init),
        (:ùêî, :ùêç, :ùêß)
    )

    x = eg.x
    N = length(x)

    0 <= n <= N || throw(ArgumentError("n ‚àà [1, 2, ‚Ä¶, length(x)] is required. Got n=$n and length(x)=$(length(x))"))

    wte = _walkthrough_entropy(n, N, ùêç, ùêß; length_normalize = length_normalize, base = base)
    return convert(Float64, wte)
end


"""
    walkthrough_entropy(x, n::Int; base = MathConstants.e)

Compute the walk-through entropy (Stoop et al., 2021)[^Stoop2021] to the given `base` at
position `n` for a symbol sequence `x`, where `x` can be any categorical iterable.

If computing the walkthrough entropy for multiple `n`, use [`entropygenerator`](@ref) with
    [`WalkthroughEntropy`](@ref).

!!! info
    This estimator is only available for entropy estimation. Probabilities
    cannot be obtained directly.


## Examples

```jldoctest; setup = :(using Entropies)
julia> x = "abc"^10
"abcabcabcabcabcabcabcabcabcabc"

julia> walkthrough_entropy(x, 5)
1.9512293105329133
```

[^Stoop2021]: Stoop, R. L., Stoop, N., Kanders, K., & Stoop, R. (2021). Excess entropies suggest the physiology of neurons to be primed for higher-level computation. Physical Review Letters, 127(14), 148101.
"""
function walkthrough_entropy(x, n::J, base = MathConstants.e) where {J <: Integer}
    g = entropygenerator(x, WalkthroughEntropy())
    # The length-normalized walkthrough entropy is the excess entropy, so here we never
    # normalize.
    return g(n; base = base, length_normalize = false)
end

function walkthrough_entropy(x, n::AbstractVector{J};
        base = MathConstants.e) where {J <: Integer}

    g = entropygenerator(x, WalkthroughEntropy())
    # The length-normalized walkthrough entropy is the excess entropy, so here we never
    # normalize.
    return [g(n·µ¢; base = base, length_normalize = false) for n·µ¢ in n]
end
