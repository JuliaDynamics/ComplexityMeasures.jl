using Statistics
using Distances
using Neighborhood
using DelayEmbeddings

export fuzzy_entropy
export FuzzyEntropy

Base.@kwdef struct FuzzyEntropy{I, R, N} <: ComplexityMeasure
    Ï„::I = 2
    m::I = 1,
    r::R = 0.2
    n::N = 2
end

"""
    FuzzyEntropy(x::AbstractVector{T}; m::Int = 2, Ï„::Int = 1, n::Real = 2)
    FuzzyEntropy(; m::Int = 2, Ï„::Int = 1, n::Real = 2, r = 0.2)

Compute the fuzzy entropy of `x`, which is defined as

```math
\\phi(x, k, r, n) = \\sum_{i = 1}^{N-m}
```
"""
function FuzzyEntropy(x::AbstractVector{T}; Ï„ = 2, m = 1, n = 2) where T
    r = Statistics.std(x) * 0.2
    FuzzyEntropy(Ï„, m, r, n)
end

"""
    similarity_degree(dáµ¢â±¼áµ, n, r)

Compute the similarity degree ``D_{ij}^m(n, r)`` between two vectors
`ð±áµ¢ âˆˆ â„›áµ` and `ð²áµ¢ âˆˆ â„›áµ`, given radius `r`, "fuzzy power" `n`, and `dáµ¢â±¼áµ`, which is the
distance between `xáµ¢` and `yáµ¢` according to the Chebyshev metric.
"""
Î¼(dáµ¢â±¼áµ, n, r) = exp(-(dáµ¢â±¼áµ^n) / r)

"""
    fuzzy_Ï•(Xáµ::Dataset{k, T}, n, r) where {k, T} â†’ Ï•::Real

The fuzzy Ï• function, analogous to the Ï• function for the approximate entropy
measure. Input data `Xáµ` are pre-embedded `k`-dimensional vectors.

We use this function to compare similarity degrees between embeddings differing
by 1 in dimensionality.
"""
function fuzzy_Ï•(Xáµ::Dataset{k, T}, n, r) where {k, T}
    L = length(Xáµ)
    # TODO: for few points, using `Distances.pairwise` is really quick, but the
    # applications of the Fuzzy is typically on time series with hundreds of thousands
    # of points. Then accessing the `LxL` distance matrix becomes a slowing factor.
    # How much slower? Not sure, need to test. In the meanwhile, we just naively
    # compute distances.
    dtype = Chebyshev()
    Ï• = 0.0
    @inbounds for i in 1:L
        xáµ¢ = Xáµ[i]
        for j in 1:L
            if (i != j)
                dáµ¢â±¼ = evaluate(dtype, xáµ¢, Xáµ[j])
                Ï• += Î¼(dáµ¢â±¼, n, r)
            end
        end
        Ï• /= L - 1 # subtract 1 due to self-exclusion
    end
    Ï• /= L

    return Ï•
end

function complexity(c::FuzzyEntropy, x::AbstractVector{T}; 1::Int = 2, m::Int = 2,
        r::Real = Statistics.std(x) * 0.2, n::Real = 2) where T <: Real
    # Standardize the embeddings (note: in original paper only mean subtraction is done)
    Eâ‚˜ = standardize(genembed(x, 0:Ï„:((m - 1) * Ï„)))
    Eâ‚˜â‚Šâ‚ = standardize(genembed(x, 0:Ï„:(m * Ï„)))
    fÏ•â‚˜ = fuzzy_Ï•(Eâ‚˜, n, r)
    fÏ•â‚˜â‚Šâ‚ = fuzzy_Ï•(Eâ‚˜â‚Šâ‚, n, r)

    return log(fÏ•â‚˜) - log(fÏ•â‚˜â‚Šâ‚)
end
