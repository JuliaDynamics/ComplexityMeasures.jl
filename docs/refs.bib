@article{Li2019,
  title={Reverse dispersion entropy: a new complexity measure for sensor signal},
  author={Li, Yuxing and Gao, Xiang and Wang, Long},
  journal={Sensors},
  volume={19},
  number={23},
  pages={5203},
  year={2019},
  publisher={MDPI}
}

@article{Zhou2023,
  title={Using missing dispersion patterns to detect determinism and nonlinearity in time series data},
  author={Zhou, Qin and Shang, Pengjian and Zhang, Boyi},
  journal={Nonlinear Dynamics},
  volume={111},
  number={1},
  pages={439--458},
  year={2023},
  publisher={Springer}
}

@article{Curado2004,
  title={On the stability of analytic entropic forms},
  author={Curado, Evaldo MF and Nobre, Fernando D},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={335},
  number={1-2},
  pages={94--106},
  year={2004},
  publisher={Elsevier}
}
@article{Anteneodo1999,
  title={Maximum entropy approach to stretched exponential probability distributions},
  author={Anteneodo, C and Plastino, Angel R},
  journal={Journal of Physics A: Mathematical and General},
  volume={32},
  number={7},
  pages={1089},
  year={1999},
  publisher={IOP Publishing}
}

@article{Rostaghi2016,
  title={Dispersion entropy: A measure for time-series analysis},
  author={Rostaghi, Mostafa and Azami, Hamed},
  journal={IEEE Signal Processing Letters},
  volume={23},
  number={5},
  pages={610--614},
  year={2016},
  publisher={IEEE}
}

@article{Li2018,
  title={Noise reduction method of underwater acoustic signals based on CEEMDAN, effort-to-compress complexity, refined composite multiscale dispersion entropy and wavelet threshold denoising},
  author={Li, Guohui and Guan, Qianru and Yang, Hong},
  journal={Entropy},
  volume={21},
  number={1},
  pages={11},
  year={2018},
  publisher={MDPI}
}

@article{Li2019,
  title={Reverse dispersion entropy: a new complexity measure for sensor signal},
  author={Li, Yuxing and Gao, Xiang and Wang, Long},
  journal={Sensors},
  volume={19},
  number={23},
  pages={5203},
  year={2019},
  publisher={MDPI}
}

@article{Azami2017,
  title={Refined composite multiscale dispersion entropy and its application to biomedical signals},
  author={Azami, Hamed and Rostaghi, Mostafa and Ab{\'a}solo, Daniel and Escudero, Javier},
  journal={IEEE Transactions on Biomedical Engineering},
  volume={64},
  number={12},
  pages={2872--2879},
  year={2017},
  publisher={IEEE}
}

@article{Costa2002,
  title={Multiscale entropy analysis of complex physiologic time series},
  author={Costa, Madalena and Goldberger, Ary L and Peng, C-K},
  journal={Physical review letters},
  volume={89},
  number={6},
  pages={068102},
  year={2002},
  publisher={APS}
}

@article{Costa2015,
  title={Generalized multiscale entropy analysis: Application to quantifying the complex volatility of human heartbeat time series},
  author={Costa, Madalena D and Goldberger, Ary L},
  journal={Entropy},
  volume={17},
  number={3},
  pages={1197--1203},
  year={2015},
  publisher={MDPI}
}

@article{Pincus1991,
  title={Approximate entropy as a measure of system complexity.},
  author={Pincus, Steven M},
  journal={Proceedings of the National Academy of Sciences},
  volume={88},
  number={6},
  pages={2297--2301},
  year={1991},
  publisher={National Acad Sciences}
}

@article{LempelZiv1976,
  title={On the complexity of finite sequences},
  author={Lempel, Abraham and Ziv, Jacob},
  journal={IEEE Transactions on information theory},
  volume={22},
  number={1},
  pages={75--81},
  year={1976},
  publisher={IEEE}
}

@article{Amigó2004,
  title={Estimating the entropy rate of spike trains via Lempel-Ziv complexity},
  author={Amig{\'o}, Jos{\'e} M and Szczepa{\'n}ski, Janusz and Wajnryb, Elek and Sanchez-Vives, Maria V},
  journal={Neural Computation},
  volume={16},
  number={4},
  pages={717--736},
  year={2004},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{Richman2000,
  title={Physiological time-series analysis using approximate entropy and sample entropy},
  author={Richman, Joshua S and Moorman, J Randall},
  journal={American journal of physiology-heart and circulatory physiology},
  volume={278},
  number={6},
  pages={H2039--H2049},
  year={2000},
  publisher={American Physiological Society Bethesda, MD}
}

@article{Rosso2007,
  title={Distinguishing noise from chaos},
  author={Rosso, Osvaldo A and Larrondo, HA and Martin, Mar{\'\i}a Teresa and Plastino, A and Fuentes, Miguel A},
  journal={Physical review letters},
  volume={99},
  number={15},
  pages={154102},
  year={2007},
  publisher={APS}
}

@article{Rosso2013,
  title={Generalized statistical complexity: A new tool for dynamical systems},
  author={Rosso, Osvaldo A and Mart{\'\i}n, MT and Larrondo, Hilda A and Kowalski, AM and Plastino, A},
  journal={Concepts and recent advances in generalized information measures and statistics},
  pages={169--215},
  year={2013},
  publisher={Bentham Science Publishers Emirate of Sharjah, United Arab Emirates}
}

@article{Sippel2016,
  title={statcomp: Statistical Complexity and Information measures for time series analysis},
  author={Sippel, S and Lange, H and Gans, F},
  journal={R package version},
  year={2016}
}

@inproceedings{Gao2015,
  title={Efficient estimation of mutual information for strongly dependent variables},
  author={Gao, Shuyang and Ver Steeg, Greg and Galstyan, Aram},
  booktitle={Artificial intelligence and statistics},
  pages={277--286},
  year={2015},
  organization={PMLR}
}

@article{Singh2003,
  title={Nearest neighbor estimates of entropy},
  author={Singh, Harshinder and Misra, Neeraj and Hnizdo, Vladimir and Fedorowicz, Adam and Demchuk, Eugene},
  journal={American journal of mathematical and management sciences},
  volume={23},
  number={3-4},
  pages={301--321},
  year={2003},
  publisher={Taylor \& Francis}
}

@article{Goria2005,
  title={A new class of random vector entropy estimators and its applications in testing statistical hypotheses},
  author={Goria, Mohammed Nawaz and Leonenko, Nikolai N and Mergel, Victor V and Novi Inverardi, Pier Luigi},
  journal={Journal of Nonparametric Statistics},
  volume={17},
  number={3},
  pages={277--297},
  year={2005},
  publisher={Taylor \& Francis}
}

@article{KozachenkoLeonenko1987,
  title={Sample estimate of the entropy of a random vector},
  author={Kozachenko, Lyudmyla F and Leonenko, Nikolai N},
  journal={Problemy Peredachi Informatsii},
  volume={23},
  number={2},
  pages={9--16},
  year={1987},
  publisher={Russian Academy of Sciences, Branch of Informatics, Computer Equipment and~…}
}

@article{Charzyńska2015,
  title={Improvement of the k-NN entropy estimator with applications in systems biology},
  author={Charzy{\'n}ska, Agata and Gambin, Anna},
  journal={Entropy},
  volume={18},
  number={1},
  pages={13},
  year={2015},
  publisher={MDPI}
}

@article{Kraskov2004,
  title={Estimating mutual information},
  author={Kraskov, Alexander and St{\"o}gbauer, Harald and Grassberger, Peter},
  journal={Physical review E},
  volume={69},
  number={6},
  pages={066138},
  year={2004},
  publisher={APS}
}

@article{Lord2018,
  title={Geometric k-nearest neighbor estimation of entropy and mutual information},
  author={Lord, Warren M and Sun, Jie and Bollt, Erik M},
  journal={Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume={28},
  number={3},
  year={2018},
  publisher={AIP Publishing}
}

@article{Zhu2015,
  title={Contribution to transfer entropy estimation via the k-nearest-neighbors approach},
  author={Zhu, Jie and Bellanger, Jean-Jacques and Shu, Huazhong and Le Bouquin Jeann{\`e}s, R{\'e}gine},
  journal={Entropy},
  volume={17},
  number={6},
  pages={4173--4201},
  year={2015},
  publisher={MDPI}
}

@article{Alizadeh2010,
  title={A new estimator of entropy},
  author={Alizadeh, Noughabi Hadi and Arghami, Naser Reza},
  year={2010},
  journal={Journal of the Iranian Statistical Society (JIRSS)},
  publisher={Journal of the Iranian Statistical Society (JIRSS)}
}

@article{Correa1995,
  title={A new estimator of entropy},
  author={Correa, Juan C},
  journal={Communications in Statistics-Theory and Methods},
  volume={24},
  number={10},
  pages={2439--2449},
  year={1995},
  publisher={Taylor \& Francis}
}

@article{Ebrahimi1994,
  title={Two measures of sample entropy},
  author={Ebrahimi, Nader and Pflughoeft, Kurt and Soofi, Ehsan S},
  journal={Statistics \& Probability Letters},
  volume={20},
  number={3},
  pages={225--234},
  year={1994},
  publisher={Elsevier}
}

@article{Vasicek1976,
  title={A test for normality based on sample entropy},
  author={Vasicek, Oldrich},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={38},
  number={1},
  pages={54--59},
  year={1976},
  publisher={Oxford University Press}
}

@article{Chao2003,
  title={Nonparametric estimation of Shannon’s index of diversity when there are unseen species in sample},
  author={Chao, Anne and Shen, Tsung-Jen},
  journal={Environmental and ecological statistics},
  volume={10},
  pages={429--443},
  year={2003},
  publisher={Springer}
}

@article{Arora2022,
  title={Estimating the entropy of linguistic distributions},
  author={Arora, Aryaman and Meister, Clara and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2204.01469},
  year={2022}
}

@article{Horvitz1952,
  title={A generalization of sampling without replacement from a finite universe},
  author={Horvitz, Daniel G and Thompson, Donovan J},
  journal={Journal of the American statistical Association},
  volume={47},
  number={260},
  pages={663--685},
  year={1952},
  publisher={Taylor \& Francis}
}

@article{Zahl1977,
  title={Jackknifing an index of diversity},
  author={Zahl, Samuel},
  journal={Ecology},
  volume={58},
  number={4},
  pages={907--913},
  year={1977},
  publisher={Wiley Online Library}
}

@article{Miller1955,
  title={Note on the bias of information estimates},
  author={Miller, George},
  journal={Information theory in psychology: Problems and methods},
  year={1955},
  publisher={Free Press}
}

@article{Paninski2003,
  title={Estimation of entropy and mutual information},
  author={Paninski, Liam},
  journal={Neural computation},
  volume={15},
  number={6},
  pages={1191--1253},
  year={2003},
  publisher={MIT Press}
}

@article{Grassberger2022,
  title={On generalized Sch{\"u}rmann entropy estimators},
  author={Grassberger, Peter},
  journal={Entropy},
  volume={24},
  number={5},
  pages={680},
  year={2022},
  publisher={MDPI}
}

@article{Berger2019,
  title={Teaching ordinal patterns to a computer: Efficient encoding algorithms based on the Lehmer code},
  author={Berger, Sebastian and Kravtsiv, Andrii and Schneider, Gerhard and Jordan, Denis},
  journal={Entropy},
  volume={21},
  number={10},
  pages={1023},
  year={2019},
  publisher={MDPI}
}

@article{Lad2015,
author = {Frank Lad and Giuseppe Sanfilippo and Gianna Agr{\`o}},
title = {{Extropy: Complementary Dual of Entropy}},
volume = {30},
journal = {Statistical Science},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {40 -- 58},
keywords = {Bregman divergence, Differential and relative entropy/extropy, Duality, Gini index of heterogeneity, Kullback–Leibler divergence, proper scoring rules, repeat rate},
year = {2015},
doi = {10.1214/14-STS430},
URL = {https://doi.org/10.1214/14-STS430}
}


@book{Ahlswede2006,
  title={General theory of information transfer and combinatorics},
  author={Ahlswede, Rudolf and B{\"a}umer, Lars and Cai, Ning and Aydinian, Harout and Blinovsky, Vladimir and Deppe, Christian and Mashurian, Haik},
  volume={68},
  year={2006},
  publisher={Springer}
}

@book{Ahlswede2021,
  title={Identification and Other Probabilistic Models},
  author={Ahlswede, Rudolf and Ahlswede, Alexander and Alth{\"o}fer, Ingo and Deppe, Christian and Tamm, Ulrich},
  year={2021},
  publisher={Springer}
}

@book{Tsallis2009,
  title={Introduction to nonextensive statistical mechanics: approaching a complex world},
  author={Tsallis, Constantino},
  volume={1},
  number={1},
  year={2009},
  publisher={Springer}
}

@article{Liu2023,
  title={Renyi extropy},
  author={Liu, Jiali and Xiao, Fuyuan},
  journal={Communications in Statistics-Theory and Methods},
  volume={52},
  number={16},
  pages={5836--5847},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{Shannon1948,
  title={A mathematical theory of communication},
  author={Shannon, Claude Elwood},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}

@misc{Rényi1961,
  title={Proceedings of the fourth Berkeley symposium on mathematical statistics and probability},
  author={Eden, M},
  year={1961},
  publisher={University of California Press Berkeley}
}

@article{Xue2023,
  title={Tsallis extropy},
  author={Xue, Yige and Deng, Yong},
  journal={Communications in Statistics-Theory and Methods},
  volume={52},
  number={3},
  pages={751--762},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{Tsallis1988,
  title={Possible generalization of Boltzmann-Gibbs statistics},
  author={Tsallis, Constantino},
  journal={Journal of statistical physics},
  volume={52},
  pages={479--487},
  year={1988},
  publisher={Springer}
}

@article{Wu2013,
  title={Time series analysis using composite multiscale entropy},
  author={Wu, Shuen-De and Wu, Chiu-Wen and Lin, Shiou-Gwo and Wang, Chun-Chieh and Lee, Kung-Yen},
  journal={Entropy},
  volume={15},
  number={3},
  pages={1069--1084},
  year={2013},
  publisher={MDPI}
}

@article{Wang2020,
  title={Multiscale diversity entropy: A novel dynamical measure for fault diagnosis of rotating machinery},
  author={Wang, Xianzhi and Si, Shubin and Li, Yongbo},
  journal={IEEE Transactions on Industrial Informatics},
  volume={17},
  number={8},
  pages={5419--5429},
  year={2020},
  publisher={IEEE}
}

@article{PrichardTheiler1995,
  title={Generalized redundancies for time series analysis},
  author={Prichard, Dean and Theiler, James},
  journal={Physica D: Nonlinear Phenomena},
  volume={84},
  number={3-4},
  pages={476--493},
  year={1995},
  publisher={Elsevier}
}

@article{Llanos2017,
  title={Power spectral entropy as an information-theoretic correlate of manner of articulation in American English},
  author={Llanos, Fernando and Alexander, Joshua M and Stilp, Christian E and Kluender, Keith R},
  journal={The Journal of the Acoustical Society of America},
  volume={141},
  number={2},
  pages={EL127--EL133},
  year={2017},
  publisher={AIP Publishing}
}

@article{Tian2017,
  title={Spectral entropy can predict changes of working memory performance reduced by short-time training in the delayed-match-to-sample task},
  author={Tian, Yin and Zhang, Huiling and Xu, Wei and Zhang, Haiyong and Yang, Li and Zheng, Shuxing and Shi, Yupan},
  journal={Frontiers in human neuroscience},
  volume={11},
  pages={437},
  year={2017},
  publisher={Frontiers Media SA}
}

@article{BandtPompe2002,
  title={Permutation entropy: a natural complexity measure for time series},
  author={Bandt, Christoph and Pompe, Bernd},
  journal={Physical review letters},
  volume={88},
  number={17},
  pages={174102},
  year={2002},
  publisher={APS}
}

@article{Zunino2017,
  title={Permutation entropy based time series analysis: Equalities in the input signal can lead to false conclusions},
  author={Zunino, Luciano and Olivares, Felipe and Scholkmann, Felix and Rosso, Osvaldo A},
  journal={Physics Letters A},
  volume={381},
  number={22},
  pages={1883--1892},
  year={2017},
  publisher={Elsevier}
}

@article{He2016,
  title={Multivariate permutation entropy and its application for complexity analysis of chaotic systems},
  author={He, Shaobo and Sun, Kehui and Wang, Huihai},
  journal={Physica A: Statistical Mechanics and its Applications},
  volume={461},
  pages={812--823},
  year={2016},
  publisher={Elsevier}
}

@article{Fadlallah2013,
  title={Weighted-permutation entropy: A complexity measure for time series incorporating amplitude information},
  author={Fadlallah, Bilal and Chen, Badong and Keil, Andreas and Pr{\'\i}ncipe, Jos{\'e}},
  journal={Physical Review E},
  volume={87},
  number={2},
  pages={022911},
  year={2013},
  publisher={APS}
}

@article{Azami2016,
  title={Amplitude-aware permutation entropy: Illustration in spike detection and signal segmentation},
  author={Azami, Hamed and Escudero, Javier},
  journal={Computer methods and programs in biomedicine},
  volume={128},
  pages={40--51},
  year={2016},
  publisher={Elsevier}
}

@article{Rosso2001,
  title={Wavelet entropy: a new tool for analysis of short duration brain electrical signals},
  author={Rosso, Osvaldo A and Blanco, Susana and Yordanova, Juliana and Kolev, Vasil and Figliola, Alejandra and Sch{\"u}rmann, Martin and Ba{\c{s}}ar, Erol},
  journal={Journal of neuroscience methods},
  volume={105},
  number={1},
  pages={65--75},
  year={2001},
  publisher={Elsevier}
}

@article{Azami2019,
  title={Two-dimensional dispersion entropy: An information-theoretic method for irregularity analysis of images},
  author={Azami, Hamed and da Silva, Luiz Eduardo Virgilio and Omoto, Ana Carolina Mieko and Humeau-Heurtier, Anne},
  journal={Signal Processing: Image Communication},
  volume={75},
  pages={178--187},
  year={2019},
  publisher={Elsevier}
}

@article{Ribeiro2012,
    doi = {10.1371/journal.pone.0040689},
    author = {Ribeiro, Haroldo V., Zunino, Luciano, Lenzi, Ervin K., Santoro, Perseu A., Mendes, Renio S.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Complexity-Entropy Causality Plane as a Complexity Measure for Two-Dimensional Patterns},
    year = {2012},
    month = {08},
    volume = {7},
    url = {https://doi.org/10.1371/journal.pone.0040689},
    pages = {1-9},
    abstract = {Complexity measures are essential to understand complex systems and there are numerous definitions to analyze one-dimensional data. However, extensions of these approaches to two or higher-dimensional data, such as images, are much less common. Here, we reduce this gap by applying the ideas of the permutation entropy combined with a relative entropic index. We build up a numerical procedure that can be easily implemented to evaluate the complexity of two or higher-dimensional patterns. We work out this method in different scenarios where numerical experiments and empirical data were taken into account. Specifically, we have applied the method to  fractal landscapes generated numerically where we compare our measures with the Hurst exponent;  liquid crystal textures where nematic-isotropic-nematic phase transitions were properly identified;  12 characteristic textures of liquid crystals where the different values show that the method can distinguish different phases;  and Ising surfaces where our method identified the critical temperature and also proved to be stable.},
    number = {8},

}

@article{Schlemmer2018,
  title={Spatiotemporal permutation entropy as a measure for complexity of cardiac arrhythmia},
  author={Schlemmer, Alexander and Berg, Sebastian and Lilienkamp, Thomas and Luther, Stefan and Parlitz, Ulrich},
  journal={Frontiers in Physics},
  volume={6},
  pages={39},
  year={2018},
  publisher={Frontiers Media SA}
}

@article{Diego2019,
  title={Transfer entropy computation using the Perron-Frobenius operator},
  author={Diego, David and Haaga, Kristian Agas{\o}ster and Hannisdal, Bjarte},
  journal={Physical Review E},
  volume={99},
  number={4},
  pages={042212},
  year={2019},
  publisher={APS}
}

@article{Hausser2009,
  title={Entropy inference and the James-Stein estimator, with application to nonlinear gene association networks.},
  author={Hausser, Jean and Strimmer, Korbinian},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={7},
  year={2009}
}

@incollection{JamesStein1992,
  title={Estimation with quadratic loss},
  author={James, William and Stein, Charles},
  booktitle={Breakthroughs in statistics: Foundations and basic theory},
  pages={443--460},
  year={1992},
  publisher={Springer}
}

@article{Schurmann2004,
  title={Bias analysis in entropy estimation},
  author={Sch{\"u}rmann, Thomas},
  journal={Journal of Physics A: Mathematical and General},
  volume={37},
  number={27},
  pages={L295},
  year={2004},
  publisher={IOP Publishing}
}